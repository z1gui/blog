<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>子规入梧桐</title>
  
  <subtitle>z1gui</subtitle>
  <link href="https://www.lazydaily.cn/atom.xml" rel="self"/>
  
  <link href="https://www.lazydaily.cn/"/>
  <updated>2025-05-20T07:21:06.990Z</updated>
  <id>https://www.lazydaily.cn/</id>
  
  <author>
    <name>z1gui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「持续更新」AI辅助编程使用心得</title>
    <link href="https://www.lazydaily.cn/761386768996888/"/>
    <id>https://www.lazydaily.cn/761386768996888/</id>
    <published>2025-05-12T16:00:00.000Z</published>
    <updated>2025-05-20T07:21:06.990Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。</p><p>早在 2024 年初，我就开始接触 AI 编程，一开始就使用了 Cursor。当我熟悉了它的操作之后，惊叹于它输出代码的质量。随后，我向身边朋友，同事极力推荐 Cursor。</p><p>本质上，Cursor 是一个集成 AI 能力的 VS Code 编辑器。尽管后来尝试各个大厂的不同的 AI 编程工具，例如：通义灵码，Windsurf，Trae 等，甚至自己搭建平台调用 Deepseek Api 完成编程辅助工作，但坦言来讲，体验都不如 Cursor。</p><h2 id="Cursor-收费模式"><a href="#Cursor-收费模式" class="headerlink" title="Cursor 收费模式"></a>Cursor 收费模式</h2><p>当然，Cursor 并不是免费的。它的收费方式是订阅制，订阅价格在 $20 &#x2F; 月。其中包含 500 次快请求，以及不限次数的慢请求。说实话，每月 140 块钱确实让人望而却步。</p><p><img src="/img/Pastedimage20250514161308.png" alt="Cursor收费模式"></p><p>Cursor 相对新用户还是有很好的政策。新用户首月 14 天 150 次快请求，次月及以后每月 50 次快请求，用完就不能再使用了。理论上有足够多的账号，也可以白嫖。在没有教育优惠前，我就是用两个账号的试用和免费请求体验了 cursor 的绝大数功能。</p><blockquote><p>个人使用来说，我一般使用 cursor 调整前端样式，或者解决前端报错问题。或者直接需求文档丢给 cursor 让他给我生成前端文件。50 次请求大概能完成 2~3 个复杂功能页面的开发。</p></blockquote><h2 id="Cursor-教育优惠"><a href="#Cursor-教育优惠" class="headerlink" title="Cursor 教育优惠"></a>Cursor 教育优惠</h2><p>2025 年 5 月 8 号上午，cursor 开放教育优惠。凭借学生身份可以申请为期 1 年的 pro 会员。但是因为中国用户申请过多，在当天下午取消 CN 节点。目前可以用国外 edu 邮箱+学生信息验证，推荐咸鱼，一般来说 ￥100~200 不等可以搞定成品号。</p><p>目前，我使用的就是 Cursor 教育优惠。在咸鱼上搜 Cursor 教育优惠，用￥120 购买一个 <a href="http://www.sjsu.edu/">SAN JOSÉ STATE UNIVERSITY</a> 的 edu 邮箱和绑定信息。操作相对简单，只需要绑定登录邮箱，申请 Cursor 教育优惠认证即可（过程中可能需要绑定支付宝 0 元订阅，订阅成功之后可直接取消订阅，不影响当前订阅）。如果后续还有学生认证，可以转发 edu 邮箱到自己常用邮箱，这样就不会错过认证邮件。</p><blockquote><p>2025-5-20：订阅时间从 2025 年 5 月 12 号到 2026 年 5 月 12 号，当前使用无问题，后续有问题补充</p></blockquote><p><img src="/img/Pastedimage20250520090726.png" alt="Pro会员状态"></p><p>目前来说，500 次快请求基本满足个人高强度使用的要求。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。</summary>
      
    
    
    
    <category term="AI" scheme="https://www.lazydaily.cn/categories/AI/"/>
    
    
    <category term="Cursor" scheme="https://www.lazydaily.cn/tags/Cursor/"/>
    
  </entry>
  
  <entry>
    <title>为什么一定要有一个个人网站？</title>
    <link href="https://www.lazydaily.cn/cmb8pcxdj0003gfp8211v6tgv/"/>
    <id>https://www.lazydaily.cn/cmb8pcxdj0003gfp8211v6tgv/</id>
    <published>2025-04-23T16:00:00.000Z</published>
    <updated>2025-05-26T03:00:41.285Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。</p><h2 id="为什么建立这个网站"><a href="#为什么建立这个网站" class="headerlink" title="为什么建立这个网站"></a>为什么建立这个网站</h2><p>在此网站建立之前，我通常在CSDN上写作。</p><p>但随着时间推移，我开始发现，CSDN上的文章， Although it is very good, but it is not very good for SEO。尽管我在CSDN上没有很多有质量的输出，但是繁杂的信息流却充斥在我面前。关注，点赞，私信，评论，活动等等都是我要面对的。这些信息流无时无刻不在分散我的注意力，使我感到非常痛苦。</p><p>因此，我开始探索更有效的方式。前几年微信公众号爆火，我本人也关注不少微信公众号。其中，有非常多关于编程的公众号对我帮助极大，我非常喜欢。时常幻想自己能够在公众号上写好文章，这样我就可以分享自己的知识了，或者说更纯粹的分享自己的知识了。</p><p>我也的确这么做了，「整点儿代码」就是尝试。「整点儿代码」最初的规划是，每天产出一篇文章，设置定时晚上10点左右发布，这也 call back 了“整点”这个 concept。可惜，我并没有成功。一方面微信公众号的审核不通过导致不能整点发布，让我十分困扰。另一方面，就是个人没有坚持下来。最重要的一点是，我仍然没有从关注，点赞，私信，评论中脱离出来。是的，公众号也有这样的问题需要我面对。显然，这不是我想要的、理想的博客记录方式。</p><p>最终，我决定做一个自己的博客网站。</p><h2 id="建站过程"><a href="#建站过程" class="headerlink" title="建站过程"></a>建站过程</h2><p>2022 年，我了解到，GitHub Pages 是一个非常优秀的博客托管平台。基于 Git 方式的 post 和自动化发布节省了我不少的时间，也使我更专注于内容的编写。确定了服务托管方式，剩下的工作就是考虑网站搭建技术方向了。互联网上关于博客类网站建设的技术已经非常成熟了，Wordpress，Vuepress，Docsify，Hexo，Next.js 等等。</p><h3 id="Docsify"><a href="#Docsify" class="headerlink" title="Docsify"></a>Docsify</h3><p>最开始时候，我比较欣赏 Docsify 这种静态简单的风格。Docsify 本身支持的插件丰富，包括评论系统，访问次数，字数统计，页面搜索等，可以大大节省自己开发的时间。此外，将项目部署到 Github 上，使用 Github Page 托管之后，不用维护本地文档。编写文章发布也不需要编译，只要提交文件，等待自动部署即可。</p><p><img src="/img/Pastedimage20250514170304.png" alt="Pasted image 20250514170304.png"></p><p><img src="/img/Pastedimage20250514170358.png" alt="Pasted image 20250514170358.png"></p><p>你可以访问 <a href="https://z1gui.github.io/chips/#/"> https://z1gui.github.io/chips/#/ </a> 来查看页面。该项目搭建具体参考了<a href="https://bugstack.cn/">小傅哥</a>的这篇博客 <a href="https://blog.csdn.net/generalfu/article/details/123268118?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522815fa9b0be7b0090fc06b78edb862108%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=815fa9b0be7b0090fc06b78edb862108&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-123268118-null-null.nonecase&utm_term=docsify&spm=1018.2226.3001.4450">《# 在GitHub&#x2F;Gitee上，搭建一个简单的所见即所得博客》</a>。如果你觉得这个样式符合自己的审美，也可以参考我仓库里面的这个项目 <a href="https://github.com/z1gui/chips"> https://github.com/z1gui/chips </a> 配置。</p><p>期间，我还尝试将 Docsify 部署到云服务器上，后来发现不如在 Github 上好管理，遂放弃。</p><h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>再后来，我发现 docsify 很好，但是不够好。在文章展示，以及必要插件上，docsify 能满足一个博客的基础功能。但是，docsify 没有标签，分类，归档等功能。虽然我不追求极致的动效和交互效果，但 Docsify 过于简单的交互效果，让我感觉在阅读一个在线的 markdown 阅读器。与此同时，在 V2ex 的 VXNA 模块看过太多优秀博主的博客，让我又一次萌生了改博客样式的念头。</p><h2 id="如何写好自己的博客"><a href="#如何写好自己的博客" class="headerlink" title="如何写好自己的博客"></a>如何写好自己的博客</h2><p>从一开始下定决心写博客，我也是迷茫的。什么写，什么不写，这些很难形成一个标准。</p><p>究其原因，大部分在写博客的时候，我都在想如何让读者读明白，又如何让读者快速理解。参考我早期的博客就能看出来，有些概念太想解释清楚，以至于长篇大论，尽管它可能很简单。 后来，我意识到博客其实是给自己的知识做沉淀，目的是让自己 “知其所以然”。以这个思想来写博客，会发现写好博客并不难。</p><p>这是关于《如何写好自己的博客》我想说的其一，<strong>「以自己为中心，让自己 “知其所以然”」。</strong> 大多数人写博客是为了提升自己的知识水平，提升自己的专业技能，形成一个自己的知识体系。<strong>「如何通过博客建立自己的知识体系」</strong> ，便是我想要说的其二。</p><p>后来有幸拜读 pdai 佬引用的<a href="https://pdai.tech/md/team/team-z-tixi.html">《知识体系：如何构建自己的知识体系》</a>，醍醐灌顶，感受颇多。这里引用一下文章中的话：</p><blockquote><p>我们的学习分为四阶段：输入、内化、沉淀、输出。碎片化在输入的时候用，因为信息本身是碎片化的，时间也是碎片化的，所以输入信息的时候，要碎片化。但有需要体系化的沉淀。因此碎片化的输入，加上体系化的沉淀，你就可以实现利用碎片化的时间，做体系化的学习。</p></blockquote><p>如何写好自己的博客，首先肯定是要「写」了。积极输入，时刻充电。</p><p>当然，如果在这里能帮到你，那将是我最大的荣幸！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。&lt;/p&gt;
&lt;h2 id=&quot;为什么建立这</summary>
      
    
    
    
    <category term="生活" scheme="https://www.lazydaily.cn/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="随笔" scheme="https://www.lazydaily.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript 创建执行释放过程</title>
    <link href="https://www.lazydaily.cn/176138676899684/"/>
    <id>https://www.lazydaily.cn/176138676899684/</id>
    <published>2025-02-28T16:00:00.000Z</published>
    <updated>2025-05-26T08:31:09.761Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、对象创建过程"><a href="#一、对象创建过程" class="headerlink" title="一、对象创建过程"></a>一、对象创建过程</h1><h2 id="a-内存分配"><a href="#a-内存分配" class="headerlink" title="a. 内存分配"></a>a. 内存分配</h2><ul><li>当我们创建一个对象时（无论是通过构造函数还是字面量方式），JavaScript 引擎会在内存堆（Heap）中为这个对象分配空间。堆是一个用于存储复杂数据结构（如对象和数组）的区域。</li></ul><pre><code class="language-javascript">// 创建对象并分配内存var person = new Object();person.name = &#39;Alice&#39;;person.age = 30;</code></pre><p>或</p><pre><code class="language-javascript">// 字面量方式创建对象并分配内存var person = &#123;  name: &#39;Alice&#39;,  age: 30&#125;;</code></pre><h2 id="b-构造函数调用"><a href="#b-构造函数调用" class="headerlink" title="b. 构造函数调用"></a>b. 构造函数调用</h2><ul><li>如果使用 <code>new</code> 关键字调用构造函数来创建对象，引擎会先创建一个新的空对象，然后将该对象的原型指向构造函数的 <code>prototype</code> 属性，并将新对象作为上下文（<code>this</code>）执行构造函数内部的代码。</li></ul><pre><code class="language-javascript">function Person(name, age) &#123;  this.name = name;  this.age = age;&#125;var alice = new Person(&#39;Alice&#39;, 30);</code></pre><h1 id="二、执行过程"><a href="#二、执行过程" class="headerlink" title="二、执行过程"></a>二、执行过程</h1><h2 id="a-属性访问与方法调用"><a href="#a-属性访问与方法调用" class="headerlink" title="a. 属性访问与方法调用"></a>a. 属性访问与方法调用</h2><ul><li>在对象创建后，可以通过 <code>.</code> 或 <code>[]</code> 操作符访问和修改其属性。</li><li>可以调用对象的方法进行相关操作。</li></ul><pre><code class="language-javascript">alice.sayHello = function() &#123;  console.log(&#39;Hello, my name is &#39; + this.name);&#125;;alice.sayHello(); // 输出：Hello, my name is Alice</code></pre><h2 id="b-闭包与作用域链"><a href="#b-闭包与作用域链" class="headerlink" title="b. 闭包与作用域链"></a>b. 闭包与作用域链</h2><ul><li>函数内部可以访问外部作用域中的变量，这种特性形成了闭包。当函数被调用时，它会形成自己的执行上下文，其中包含了作用域链，作用域链用于在当前作用域以及所有父级作用域中查找变量。</li></ul><pre><code class="language-javascript">function outerFunction() &#123;  var outerVar = &#39;outer&#39;;  function innerFunction() &#123;    console.log(outerVar); // 能够访问到outerVar，这是因为闭包的作用  &#125;  innerFunction();&#125;outerFunction();</code></pre><h1 id="三、释放过程"><a href="#三、释放过程" class="headerlink" title="三、释放过程"></a>三、释放过程</h1><h2 id="a-垃圾回收机制"><a href="#a-垃圾回收机制" class="headerlink" title="a. 垃圾回收机制"></a>a. 垃圾回收机制</h2><ul><li>JavaScript 采用了自动垃圾回收机制，主要是基于可达性分析算法。简单来说，如果一个对象不再有任何引用指向它，那么这个对象就是不可达的，会被垃圾回收器视为垃圾并最终清理掉其所占用的内存资源。</li></ul><pre><code class="language-javascript">var obj1 = &#123; data: &#39;some value&#39; &#125;;var obj2 = obj1;obj1 = null; // 现在只有obj2指向原对象// 后续如果obj2也被设置为null或者超出作用域，则原对象成为不可达，会被GC回收</code></pre><h2 id="b-循环引用问题"><a href="#b-循环引用问题" class="headerlink" title="b. 循环引用问题"></a>b. 循环引用问题</h2><ul><li>当两个对象互相引用但没有其他引用指向它们时，尽管它们是不可达的，但由于互相引用导致垃圾回收器无法识别。现代浏览器和 Node. js 环境下的 V8 引擎已经实现了循环引用检测功能，但在某些情况下仍需注意避免造成循环引用。</li></ul><p>总之，在 JavaScript 中，对象从创建到销毁的过程涉及内存管理、作用域规则以及垃圾回收策略等多个方面，理解这些概念对于编写高效且无内存泄漏的 JavaScript 代码至关重要。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、对象创建过程&quot;&gt;&lt;a href=&quot;#一、对象创建过程&quot; class=&quot;headerlink&quot; title=&quot;一、对象创建过程&quot;&gt;&lt;/a&gt;一、对象创建过程&lt;/h1&gt;&lt;h2 id=&quot;a-内存分配&quot;&gt;&lt;a href=&quot;#a-内存分配&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="前端" scheme="https://www.lazydaily.cn/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="javascript" scheme="https://www.lazydaily.cn/tags/javascript/"/>
    
  </entry>
  
  <entry>
    <title>Kafka深入浅出</title>
    <link href="https://www.lazydaily.cn/761386768996831/"/>
    <id>https://www.lazydaily.cn/761386768996831/</id>
    <published>2024-12-10T16:00:00.000Z</published>
    <updated>2025-05-20T07:21:42.993Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据</p><h1 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h1><h2 id="「Kafka-是什么？主要应用场景什么？」"><a href="#「Kafka-是什么？主要应用场景什么？」" class="headerlink" title="「Kafka 是什么？主要应用场景什么？」"></a>「Kafka 是什么？主要应用场景什么？」</h2><p>Kafka 是一个分布式流式处理平台。</p><p><img src="/img/6aaf06740442599b6c52bb586545dfb8_MD5.png" alt="6aaf06740442599b6c52bb586545dfb8_MD5.png"></p><p><strong>1 . 主题</strong>：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至每类数据都创建专属的主题</p><p><strong>2 . 生产者和消费者</strong>：向主题发布消息的客户端应用程序成为生产者，生产者程序通常持续不断地向一个或者多个主题发送消息</p><p><strong>3 . Broker</strong>：集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。</p><pre><code>虽然多个 Broker 能够运行在同一台机器上，但是常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也一眼能够对外提供服务。</code></pre><p> <strong>4 . 备份机制</strong>：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本。</p><pre><code>Kafka 定义了两类副本：领导者副本和追随者副本。前者对外提供服务，即与客户端程序进行交互；后者只是被动地追随领导者副本而已，不对外进行交互。</code></pre><p><strong>5 . 分区</strong>：分区机制指的是将每个主题分成多个分区，每个分区是一组有序的消息日志</p><pre><code>生产者生产的每条消息总会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，该条消息要不在分区 0 中，要不在分区 1 中。生产者向分区中写入消息，每条消息在分区中的位置信息叫做位移。</code></pre><p><strong>6 . 消费者组</strong>：多个消费者实例共同组成一个组来消费一组主题</p><pre><code>这组主题中的每个分区只会被组内的一个消费者实例消费，其他消费者实例不能消费它消息引擎的两大模型：如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型如果所有实例属于不同的 Group，那么它实现的就是发布/订阅模型</code></pre><blockquote><p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p></blockquote><p><strong>7 . Coordinator：协调者</strong>：负责为 Group 执行 Rebalance 以及提供唯一管理和组成员管理等。</p><p><strong>8 . 消费者位移：Consumer offset</strong>：消费者消费进度，每个消费者都有自己的消费者位移</p><p><strong>9 . 重平衡：Rebalance</strong>：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。</p><p>Rebalance 是 Kafka 消费者端实现高可用的重要手段</p><p><strong>10 . AR（Assigned Replicas）</strong>：分区中的所有副本统称为 AR。</p><p>所有消息都会先发送到领导者副本，然后追随者副本才能从领导者中拉去信息进行同步</p><p>但是同步期间，追随者副本相对于领导者副本而言有一定程度的滞后，这时候追随者副本和领导者副本并非完全同步状态</p><p><strong>11 . OSR（Out Sync Replicas）</strong>：AR 的一个子集，其中都是追随者副本和领导者副本没有完全同步或者之后的副本集合</p><p><strong>12 . ISR（In Sync Replicas）</strong>：AR 的一个子集，ISR 中的副本都是和领导者副本是保持完全同步的副本。</p><p>如果某一个在 ISR 中的 follower 副本落后于 leader 副本太多，就会从 ISR 中移除，否则如果完全同步，会从 OSR 中移到 ISR 集合中</p><p><strong>13 . HW（High Watermark）</strong>：高水位，标识一个特定的消息偏移量（offset），消费者只能来取这个水位 offset 之前的消息</p><p>下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。</p><p>日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。</p><p><img src="/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png" alt="[ce77dd7ccc11dc7642aad16560000cb9_MD5.png]"></p><p><strong>14 . LEO（Log End Offset）</strong>：标识当前日志文件中下一条待写入的消息的offset</p><h1 id="二、系统架构"><a href="#二、系统架构" class="headerlink" title="二、系统架构"></a>二、系统架构</h1><p>Kafka 基础框架：一个生产者发送一个消息到 Kafka 的一个 Topic，该 Topic 的消息存放在 Broker 中，消费者订阅这个 Topic，然后从 Broker 中消费消息。</p><p>1.<strong>消息状态</strong>：在 Kafka 中，消息是否被消费的状态保存在消费者中，Broker 不会关系消息是否消费，或者被谁消费，消费者会记录一个 offset 值（指向分区中下一条被消费的消息位置），如果 offset 被错误设置可能会导致同一条消息多次消费或者丢失。</p><p>2.<strong>消息持久化</strong>：Kafka 会把消息持久化到本地文件系统中，并且具有极高的性能。</p><p>3.<strong>批量发送</strong>：Kafka 支持以消息集合为单位进行批量发送，以提高效率。</p><p>4.<strong>Push-and-Pull</strong>：Kafka 中的生产者和消费者采用的是 Push-and-Pull 模式，即生产者向 Broker Push 消息，消费者从 Broker Pull 消息。</p><p>5.<strong>分区机制</strong>：Kafka 的 Broker 是支持分区的，Producer 可以决定将消息放在哪个 Partition，在一个 Partition 中的消息顺序就是 Producer 发送消息的顺序，一个 Topic 中的 Partition 是可以配置的，Partition 是保证 Kafka 高吞吐量的重要保证。</p><p><img src="/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png" alt="[68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png]"></p><p>通常情况下，一个 Kafka 体系是包含多个 Producer，多个 Broker，多个 Consumer，以及一个 Zookeeper 集群</p><h1 id="三、生产者分区"><a href="#三、生产者分区" class="headerlink" title="三、生产者分区"></a>三、生产者分区</h1><p>一条 Kafka 消息的的组织架构是三层：主题（Topic）- 分区（Partition）- 消息（Message）</p><p>分区其实是一种负载均衡的做法。因为同一个 Topic 下的不同分区可以在不同 Broker 节点上，并且，数据读写是以分区为粒度，这样的话，每个节点都可以执行自己分区的消息的读写。除此之外，还能通过增加节点来提高吞吐量。</p><h2 id="「分区策略」"><a href="#「分区策略」" class="headerlink" title="「分区策略」"></a>「分区策略」</h2><p>所谓的分区策略其实就是决定生产者将消息发送到哪个分区的算法。</p><h3 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h3><p>如果需要自己定义分区策略，在编写生产者程序的时候，可以编写一个具体的实现类<code>org.apache.kafka.clients.producer.Partitioner</code> 接口。这接口也非常简单，只定义了两个方法：partition() 和 close() 方法。通常情况我们只需要实现 partition() 方法即可。</p><pre><code class="language-java">int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);</code></pre><p>这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。</p><h3 id="轮询策略"><a href="#轮询策略" class="headerlink" title="轮询策略"></a>轮询策略</h3><p>也称 Round-robin 策略，即顺序分配。轮询策略是 Kafka 生产者 API 默认提供的分区策略。</p><p>轮询策略有非常优秀的负载均衡表现，它总是保证消息最大限度的平均分配到所有的分区上，所以默认下它是最合理的分区策略，也是最常用的分区策略。</p><h3 id="随机策略"><a href="#随机策略" class="headerlink" title="随机策略"></a>随机策略</h3><p>也称 Randomness 策略。想要实现随机策略的 partition 方法，其实很简单，只需要两行代码即可：</p><pre><code class="language-java"> List partitions = cluster.partitionsForTopic(topic); return ThreadLocalRandom.current().nextInt(partitions.size());</code></pre><p>先计算出该主题的总分区数，然后随机返回一个小于它的正整数。</p><p>随机策略在负载均衡上面略逊于轮询策略。在老的版本里面常用随机策略，再后来的版本更新中被轮询策略所替代。</p><h3 id="按消息键保序策略"><a href="#按消息键保序策略" class="headerlink" title="按消息键保序策略"></a>按消息键保序策略</h3><p>Kafka 允许为每条消息定义消息键，简称 Key。</p><p>Key 可以为具体的业务代码，也可以用来表征消息元数据。在 Kafka 中如果消息定义了 Key，那么就可以保证同一个 Key 的消息进入相同的分区，有序分区下的消息处理是有顺序的，所以这个策略被称为安消息键保存策略。</p><p>实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：</p><pre><code class="language-java"> List partitions = cluster.partitionsForTopic(topic); return Math.abs(key.hashCode()) % partitions.size();</code></pre><p>其实，Kafka 默认的分区策略是两种：<br>如果指定了 Key ，默认实现按消息键保序策略；<br>如果未指定 Key，则使用轮询策略。</p><h3 id="「其他分区策略」"><a href="#「其他分区策略」" class="headerlink" title="「其他分区策略」"></a>「其他分区策略」</h3><p>另外还有一种比较常见的，所谓的基于地理位置的分区策略。当然这种策略只针对大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。我们可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下段代码：</p><pre><code class="language-java">List partitions = cluster.partitionsForTopic(topic);return partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();</code></pre><p>我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。</p><h1 id="四、生产者压缩算法"><a href="#四、生产者压缩算法" class="headerlink" title="四、生产者压缩算法"></a>四、生产者压缩算法</h1><p>为什么要压缩消息？压缩消息是为了更好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p><h3 id="「Kafka-是如何压缩消息的呢？」"><a href="#「Kafka-是如何压缩消息的呢？」" class="headerlink" title="「Kafka 是如何压缩消息的呢？」"></a>「Kafka 是如何压缩消息的呢？」</h3><p>Kafka 的消息层次分为两层：消息集合和消息。</p><p>??？</p><h3 id="「何时压缩？」"><a href="#「何时压缩？」" class="headerlink" title="「何时压缩？」"></a>「何时压缩？」</h3><p>在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。</p><p>在生产者程序中配置 compression.type 参数即表示弃用指定类型的压缩算法。</p><p>比如这段代码中展示了如何构建一个开启 GZIP 的 Producer 对象：</p><pre><code class="language-java">Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;acks&quot;, &quot;all&quot;);props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 开启GZIP压缩props.put(&quot;compression.type&quot;, &quot;gzip&quot;); //Producer的压缩算法是GZIPProducer producer = new KafkaProducer&lt;&gt;(props);</code></pre><p>这样 Producer 启动之后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p><p>有两种情况可能导致 Broker 重新压缩消息：</p><ul><li>情况一：Broker 端指定了和 Producer 端不同的压缩算法。</li></ul><p>一旦 Broker 端设置了不同的 compression.type 值，就一定要小心了，因为可能会发生预料之外的压缩、解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。</p><ul><li>情况二：Broker 端发生了消息格式转换。</li></ul><p>所谓的消息格式转换主要是为了兼容老版本的消费者程序。在一个生产环境中，Kafka 集群中同时保存多个版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息指向向老版本的转换。这个过程会涉及到消息的解压缩和重新压缩。一般情况下这种消息格式转换成对性能是有很大影响的，除了这里的压缩之外，他还让 Kafka 丧失了 Zero Copy 特性。</p><h3 id="「何时解压缩？」"><a href="#「何时解压缩？」" class="headerlink" title="「何时解压缩？」"></a>「何时解压缩？」</h3><p>有压缩必有解压缩！通常来说解压缩发生在消费者程序中。</p><p><strong>基本过程：Producer 端压缩，Broker 端保持，Consumer 端解压缩。</strong></p><p>注意：除了在 Consumer 端解压缩外，Broker 端也会进行解压缩。</p><p>每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能有一定的影响，特别是对 CPU 的使用率而言。</p><h3 id="「各种压缩算法对比」"><a href="#「各种压缩算法对比」" class="headerlink" title="「各种压缩算法对比」"></a>「各种压缩算法对比」</h3><p>Kafka 支持 4 种压缩算法：GZIP、Snappy 、LZ4 和 zstd(Zstandard 算法)。在实际使用中，各个算法各有千秋。</p><p>吞吐量：LZ4 &gt; Snappy &gt; zst 和 GZIP；</p><p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy；</p><p>占用宽带：zstd &lt; LZ4 和 GZIP &lt; Snappy；</p><p>在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。</p><h1 id="五、消费者组"><a href="#五、消费者组" class="headerlink" title="五、消费者组"></a>五、消费者组</h1><p>Consumer Group 是 Kafka 提供可拓展且具有容错性的消费机制。</p><p>既然是一个组，那么组内必然是可以有多个消费者或者消费者实例，它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内所有的消费者协调在一起来消费订阅主题的所有分区。每个分区只能有同一个消费组内的一个 Consumer 实例来消费。</p><h3 id="Consumer-Group-三个特性"><a href="#Consumer-Group-三个特性" class="headerlink" title="Consumer Group 三个特性"></a>Consumer Group 三个特性</h3><p>1.Consumer Group 下可以有一个或者多个 Consumer 实例，这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。</p><p>2.Group ID 是一个字符串，在一个 Kafka 集群中，它表示唯一的一个 Consumer Group。</p><p>3.Consumer Group 下所有实例订阅的主题的单独分区，只能分配给组内的某个 Consumer 实例消费，这个分区当然也可以被其他的 Group 消费。</p><p>Kafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：</p><ul><li><p>如果所有实例都是属于同一个 Group，那么它实现的是消息队列模型；</p></li><li><p>如果所有实例分别属于不同的 Group，那么它实现的就是发布&#x2F;订阅模型。</p></li></ul><h3 id="一个-Group-下应该有多少个-Consumer-实例呢？"><a href="#一个-Group-下应该有多少个-Consumer-实例呢？" class="headerlink" title="一个 Group 下应该有多少个 Consumer 实例呢？"></a>一个 Group 下应该有多少个 Consumer 实例呢？</h3><p>理想情况下，Consumer 实例的数量应该等于 Group 订阅主题的分区总数。</p><blockquote><p>假设一个 Comsumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数分别是 1，2，3，那么通常情况下，为改 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度的视线高伸缩性。</p></blockquote><h3 id="针对-Consumer-Group，Kafka-是怎么管理位移呢？"><a href="#针对-Consumer-Group，Kafka-是怎么管理位移呢？" class="headerlink" title="针对 Consumer Group，Kafka 是怎么管理位移呢？"></a>针对 Consumer Group，Kafka 是怎么管理位移呢？</h3><p>老版本 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper 是一个分布式的协调服务框架，Kafka 重度依赖它实现的各种各样的协调管理。将唯一保存到 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。</p><p>但是，慢慢的发现一个问题，即 ZooKeeper 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新是一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能。于是，新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group 的位移管理方式，采用将位移保存在 Kafka 内部主题的方法。</p><p>这个内部主题就是_counsumer_offset.</p><h1 id="六、消费者策略"><a href="#六、消费者策略" class="headerlink" title="六、消费者策略"></a>六、消费者策略</h1><p>消费者消费同一主题的哪个分区，是通过消费者策略决定的。</p><h4 id="轮询-Round"><a href="#轮询-Round" class="headerlink" title="轮询 Round"></a>轮询 Round</h4><p>Kakfa 默认的消费者策略——轮询，通过轮询方式，决定消费者消费的分区。</p><p><img src="/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png" alt="[2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png]"></p><h4 id="范围计算-Range"><a href="#范围计算-Range" class="headerlink" title="范围计算 Range"></a>范围计算 Range</h4><p>对一个消费者组来说，决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开</p><p><img src="/img/c3276b5f713b8b0641463b496c196ce2_MD5.png" alt="[c3276b5f713b8b0641463b496c196ce2_MD5.png]"></p><h4 id="范围计算升华版-Sticky"><a href="#范围计算升华版-Sticky" class="headerlink" title="范围计算升华版 Sticky"></a>范围计算升华版 Sticky</h4><p>是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离。</p><h1 id="七、位移提交"><a href="#七、位移提交" class="headerlink" title="七、位移提交"></a>七、位移提交</h1><p>假设一个分区中有 10 条消息，唯一分别是 0 到 9.</p><p>某个 Consumer 应用已经消费了 5 条消息，这就说明该 Consumer 消费了位移为 0 到 4 的 5 条消息，此时 Consumer 的位移是 5，指向了下一条消息的位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 <strong>Consumer 需要为分配给它的每一个分区提交各自的位移数据。</strong></p><p>位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。</p><p>开启自动提交位移的方法：Consumer 端有一个参数 <code>enable.auto.commint</code>，把它设置为 true 或者不设置它即可。</p><p>如果开启了自动提交，Consumer 端还有个参数：<code>auto.commit.interval.ms</code>。默认为 5 秒，表明 Kafka 每 5 秒会自动提交一次位移。</p><pre><code class="language-java">Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;group.id&quot;, &quot;test&quot;);//开启自动提交props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);//自动提交时间间隔props.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);KafkaConsumer consumer = new KafkaConsumer&lt;&gt;(props);consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));while (true) &#123;    ConsumerRecords records = consumer.poll(100);    for (ConsumerRecord record : records)        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());&#125;</code></pre><p>如果要开启手动提交，只需要将 <code>enable.auto.commit</code> 设置为 <code>false</code> 即可。</p><p>手动提交需要调用相应的 API 手动提交位移。最简单的 API 就是 <code>KafkaConsumer#commitSync()</code> 。该方法会提交 <code>KafkaConsumer#poll()</code> 返回的最新位移。从名字上来看，这是一个同步方法，即该方法会一直等待，直到位移成功提交之后才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。</p><p>下面这段代码展示了 commitSync() 的使用方法：</p><pre><code class="language-java">while (true) &#123;        ConsumerRecords records =consumer.poll(Duration.ofSeconds(1));        process(records); // 处理消息        try &#123;            consumer.commitSync();        &#125; catch (CommitFailedException e) &#123;            handle(e); // 处理提交失败异常        &#125;&#125;</code></pre><p>自动提交时，Kafka 会保证再开始调用 poll 方法时候，提交上次 poll 方法返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，然后在处理下一批消息，因此，自动提交能保证不会出消费丢失的情况。但是自动提交位移的问题在于，<strong>可能出现重复消费。</strong></p><p>手动提交的好处在于更加灵活，可以完全把控位移提交的时机和频率。但是他也有一个缺陷，就是在调用 <code>commitSync()</code> 时候会处于阻塞状态，直到远端 Broker 返回提交结果，这个状态才能结束。</p><p>这时候，手动提交的另一个方法就出现了 <code>KafkaConsumer#commitAsync()</code>。从名字上看，这是个异步操作。调用 <code>commitAsync()</code> 方法之后，它会立即返回，不会阻塞，因此不影响 Consumer 应用的 TPS（吞吐量）。由于它是异步的，Kafka 提供了一个回调函数（callback），供开发者实现提交之后的逻辑，比如记录日志或处理异常。</p><p>下面这段代码展示了调用 commintAsync() 方法：</p><pre><code class="language-java">while (true) &#123;            ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));            process(records); // 处理消息            consumer.commitAsync((offsets, exception) -&gt; &#123; if (exception != null) handle(exception);&#125;);&#125;</code></pre><p>commitAsync 的问题在于，出了问题时它不会重试。</p><p>显然，如果手动提交，我们需要将 commitSync 和 commitAsync 组合使用才能达到最理想的效果：<br>1.我们可以利用 commitSync 的自动动重试来规避那些瞬时错误，比如网络的瞬时都懂，Broker 端的 GC 问题，因为这些问题是短暂的，自动重试通常都会成功。<br>2.我们不希望程序总是处于阻塞状态，影响 TPS。</p><p>我们来看一下下面这段代码，它展示的是如何将两个 API 方法结合使用进行手动提交。</p><pre><code class="language-java">try &#123;    while(true) &#123;        ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));        process(records); // 处理消息        commitAysnc(); // 使用异步提交规避阻塞    &#125;&#125; catch(Exception e) &#123;        handle(e); // 处理异常&#125; finally &#123;      try &#123;        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交&#125; finally &#123; consumer.close();&#125;&#125;</code></pre><p>试想这样一个场景：poll 方法返回的不是 500 条消息，而是 5000 条。</p><p>那么，你肯定不想把这 5000 条消息处理完之后再提交位移，因为一旦中间出差错，之前处理的全部都要重来一遍。那么我们可以每处理完 100 条消息就提交一次位移，这样避免大批量的消息重新消费。</p><p>Kafka Consumer API 为手动提交提供了这样的方法：<code>commitSync(Map)</code> 和 <code>commitAsync(Map)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 OffsetAndMetadata 对象，保存主要是位移数据。</p><p>以 commitAsync 为例，展示一段代码。实际上，commitSync 的调用方法和它一模一样的。</p><pre><code class="language-java">private Map offsets = new HashMap&lt;&gt;();int count = 0;……while (true) &#123;    ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));        for (ConsumerRecord record: records) &#123;            process(record);  // 处理消息            offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；            if（count % 100 == 0）                consumer.commitAsync(offsets, null); // 回调处理逻辑是null                count++; &#125;&#125;</code></pre><p>与调用无参的 commitAsync 不同，这里调用了带 Map 对象参数的 commitAsync 进行细粒度的位移提交。</p><h1 id="八、重平衡"><a href="#八、重平衡" class="headerlink" title="八、重平衡"></a>八、重平衡</h1><p>重平衡 Rebalance 本质上是一种协议，规定了一个 Consumer Group 如何分配订阅 Topic 的每一个分区。Kafka 在为 Consumer Group 内的 Consumer 分配分区的过程，就是 Rebalance。</p><p>Rebalance 触发条件有三个：</p><ul><li><p>组内成员发生变化，即有新的 Consumer 实例加入组或者离开祖，或者因崩溃而退出组。</p></li><li><p>订阅主题数发生变化，Consumer Group 可以通过正则表达式方式订阅主题，比如 <code>consumer.subscribe(Pattern.compile(&quot;t.*c&quot;))</code> 就表明 Group 订阅所有以字母 t 开头、字母 c 结尾的主题，所以在 Consumer Group 运行过程中，如果创建了满足要求的主题，就会发生 Rebalance。</p></li><li><p>订阅主题的分区发生变化，Kafka 当前只能允许增加一个主题的分区数，当主题的分区数发生变化，就会触发该主题下所有 Group 的 Rebalance。</p></li></ul><h3 id="「分配策略」"><a href="#「分配策略」" class="headerlink" title="「分配策略」"></a>「分配策略」</h3><p>当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。</p><h3 id="「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」"><a href="#「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」" class="headerlink" title="「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」"></a>「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」</h3><p>在 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期的想 Coordinator 发送心跳请求，表明它还活着。如果某个 Consumer 不能及时的发送心跳请求，娜美 Coordinator 就会认为它已经死了，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。</p><p>Consumer 端设置参数里面有个：<code>session.timeout.ms</code>。默认为 10 秒，即如果 Coordinator 在 10 秒内没有收到 Group 的某个 Consumer 的心跳请求，则认为它已经挂了。除了这个参数，还有个允许开发者控制发送心跳的频率的参数，就是 <code>heartbeat.interval.ms</code>。这个参数设置越小，Consumer 发送心跳请求的频率越高。当然，请求频率越高，消耗的带宽资源也就越高。</p><p>除此之外，Consumer 端还有个参数，用于控制 Consumer 实际消费能力对对 Rebalance 的影响，即：<code>max.pool.interval.ms</code> 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。默认值为 5 分钟，表示如果 Consumer 在 5 分钟内没有消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开 Group 的请求，Coordinator 则会开启新的 Rebalance。</p><h3 id="「如何设置避免-Rebalance」"><a href="#「如何设置避免-Rebalance」" class="headerlink" title="「如何设置避免 Rebalance」"></a>「如何设置避免 Rebalance」</h3><ol><li><p>如果是因为未能及时发送心跳请求，导致 Consumer 被踢出 Group ，引发的 Rebalance。则可以设置 <code>session.timeout.ms</code> 和 <code>heartbeat.interval.ms</code> 的值。</p><ul><li><p>设置 <code>session.timeout.ms</code> &#x3D; 6s。</p></li><li><p>设置 <code>heartbeat.interval.ms</code> &#x3D; 2s。</p></li><li><p>要保证 Consumer 实例在被判定为 dead 之前，能够发送 3 条心跳请求，即 <code>session.timeout.ms &gt;= 3 * heartbeat.interval.ms</code>。</p></li></ul></li></ol><p>将 <code>session.timeout.ms</code> 设置为 6s 主要是为了让 Coordinator 能更快定位已经挂掉的 Consumer。</p><ol start="2"><li>如果是因为 Consumer 消费时间过长导致的 Rebalance。在开发过程中，为业务逻辑处理留足充足的时间，这样 Consumer 就不会因为处理这些消息太长而引起 Rebalance 了。</li></ol><h1 id="九、ConsumerOffsets"><a href="#九、ConsumerOffsets" class="headerlink" title="九、ConsumerOffsets"></a>九、ConsumerOffsets</h1><p><code>_consumer_offsets</code> 是一个 Kafka 的普通主题，它主要是保存 Kafka Consumer 的位移信息。当 Kafka 中的第一个 Consumer 启动时候，就会创建该主题。其默认分区数是 50，副本数是 3。<code>_consumer_offsets</code> 主题是一个普通的 Kafka 主题，开发者可以手动的创建、修改甚至删除它。但是它的消息格式是 Kafka 自己定义的，不能修改。开发者只能按照规定传入消息，否则内部不能成功解析，就会导致 Broker 崩溃。</p><p><code>_consumer_offsets</code> 有 3 中消息格式：</p><ul><li><p>用于保存 Consumer Group 信息的消息。</p></li><li><p>用于删除 Group 过期位移甚至删除 Group 的消息。</p></li><li><p>保存了位移值。</p></li></ul><p>前面已经提到过，Kafka 的提交方式有两种：自动提交和手动提交。</p><p>手动提交：比较灵活可控，通过调用 <code>commitSync()</code> 或者 <code>commitAsync()</code> 等 Kafka Consumer 的 API，Kafka 会向 <code>_consumer_offsets</code> 主题中写入相应的消息。</p><p>自动提交：显著优点就是省事，不用操心位移提交的事情，就能保证消息不会丢失。但是自动提交位移的有个问题，只要 Consumer 一直启动着，它就会无限期的向位移主题写入消息。</p><blockquote><p>假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。由于是自动提交位移，位移主题中会不停地写入位移&#x3D;100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。</p></blockquote><p>显然，Kafka 必须要有针对位移主题消息特点的消息删除策略，否则这种消息越多，最重撑爆整个磁盘</p><h3 id="「Compact-策略」"><a href="#「Compact-策略」" class="headerlink" title="「Compact 策略」"></a>「Compact 策略」</h3><p>Kafka 通过 Compact 策略来删除 <code>_consumer_offsets</code> 主题中的过期消息，避免该主题无限膨胀。Compact 的过程就是扫描日志的所有消息，剔除过期消息，把剩下消息整理在一起。</p><p>Kafka 提供了专门的后台线程定期的巡检待 Compact 的主题，看看是否存在猫族条件的可删除数据。这个后台线程叫做 <strong>Log cleaner</strong>。如果生产环境中出现了位移主题无限膨胀占用过多磁盘空间问题，请检查一下 Log cleaner 线程是否挂掉了。</p><h1 id="十、副本机制"><a href="#十、副本机制" class="headerlink" title="十、副本机制"></a>十、副本机制</h1><p>根据 Kafka 副本机制定义，同一个分区下面的所有副本保存有相同的消息队列，这些副本是分布在不同 Broker 中，以确保某个 Broker 宕机后其他副本可以正常使用。</p><p>在 Kafka 中，副本分为领导者副本和追随者副本。其中追随者副本不参与什么读写请求操作。追随者副本只异步拉去领导者副本，在领导者副本所在的 Broker 宕机的时候，重新从追随者副本中推选出一个领导者副本。</p><p>追随者副本唯一的工作就是，不断的从领导者副本中拉取消息，然后写入自己的提交日志中。</p><p><img src="/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png" alt="[ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png]"></p><h1 id="十一、ISR-机制"><a href="#十一、ISR-机制" class="headerlink" title="十一、ISR 机制"></a>十一、ISR 机制</h1><p>in-sync Replicas，也就是所谓的 ISR 副本集合。这个集合是动态的，而非静态不变。</p><p>ISR 中的副本一定是好 Leader 副本同步的，相反不在 ISR 中的副本一定是和 Leader 副本不同步的。</p><p>Leader 副本一定在 ISR 中，Follower 副本不一定在 ISR 中。在 Broker 端有个配置参数 <code>replica.lag.time.max.ms</code>，这个参数的含义是 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 认为 Follower 副本和 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p><h1 id="十二、Unclean-领导者选举"><a href="#十二、Unclean-领导者选举" class="headerlink" title="十二、Unclean 领导者选举"></a>十二、Unclean 领导者选举</h1><p>Kafka 将所有不在 ISR 中的副本都认为是非同步副本。在领导者选举的时候，如果选举这种副本的过程称为 Unclean 领导者选举。在 Broker 端中参数 <code>unclean.leader.election.enable</code> 控制是否开启 Unclean 领导者选举。</p><p>Unclean 领导者选举有利有弊。优点在于：因为一个分区中 Leader 副本负责读写请求，如果 Leader 副本挂了，整个分区就改了。开启 Unclean 领导者选取，会使 Leader 副本一直存在，不至于对外停止服务，提高了高可用；缺点在于：因为从 ISR 中选举 Leader 副本，就会出现数据不同步情况，就会导致数据丢失。</p><h1 id="十三、副本选举"><a href="#十三、副本选举" class="headerlink" title="十三、副本选举"></a>十三、副本选举</h1><p>Kafka 在选取 Leader 副本时候，考虑到负载均衡的平衡性，会将不同的分区的 Leader 副本分配到不同的 Broker 中，这样既能避免 Broker 宕机导致多个分区不可用，也能平衡 Broker 的负载。</p><p>Kafka 引入了优先副本的概念，优先副本的意思是，在分区的所有 AR 集合列表中的第一个副本，理想状态下就是该分区的 Leader 副本。</p><p>例如kafka集群由3台broker组成，创建了一个名为 <code>topic-partitions</code> 的topic，设置partition为3，副本数为3，partition0中AR列表为 <code>[1,2,0]</code>，那么分区0的优先副本为1</p><p><img src="/img/882565aff441558b043b911c7c240f29_MD5.png" alt="[882565aff441558b043b911c7c240f29_MD5.png]"></p><p>当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。当broker2重新恢复时，此时的kafka集群状态如下：</p><p><img src="/img/d9e50eff06b436f7621152f2739a05c5_MD5.png" alt="[d9e50eff06b436f7621152f2739a05c5_MD5.png]"></p><p>可以看到，此时broker1上负载更大，而broker2上没有负载。</p><p><strong>「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」</strong>。</p><p>比如上面的分区1，它的AR集合是<code>[2,0,1]</code>，表示分区1的优先副本就是在broker2上。</p><p>理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。</p><p><strong>「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」</strong>，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。</p><p>kafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。</p><h1 id="十四、网络通信模型"><a href="#十四、网络通信模型" class="headerlink" title="十四、网络通信模型"></a>十四、网络通信模型</h1><p><img src="/img/93681a72e52523561d8f052cb74d6da0_MD5.png" alt="[93681a72e52523561d8f052cb74d6da0_MD5.png]"></p><p>Broker 中有个<code>Acceptor(mainReactor)</code>监听新连接的到来，与新连接建连之后轮询选择一个<code>Processor(subReactor)</code>管理这个连接。</p><p>而<code>Processor</code>会监听其管理的连接，当事件到达之后，读取封装成<code>Request</code>，并将<code>Request</code>放入共享请求队列中。</p><p>然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的<code>Processor</code>的响应队列中，然后由<code>Processor</code>将<code>Response</code>返还给客户端。</p><p>每个<code>listener</code>只有一个<code>Acceptor线程</code>，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。</p><p><code>Processor</code> 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是<code>num.network.threads</code>，并且可以根据实际的业务动态增减。</p><p>还有个 IO 线程池，即<code>KafkaRequestHandlerPool</code>，执行真正的处理，对应的参数是<code>num.io.threads</code>，默认值是 8。</p><p>IO线程处理完之后会将<code>Response</code>放入对应的<code>Processor</code>中，由<code>Processor</code>将响应返还给客户端。</p><p>可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。</p><h1 id="十五、幂等性"><a href="#十五、幂等性" class="headerlink" title="十五、幂等性"></a>十五、幂等性</h1><h2 id="「幂等性Producer」"><a href="#「幂等性Producer」" class="headerlink" title="「幂等性Producer」"></a><strong>「幂等性Producer」</strong></h2><p>在 Kafka 中，Producer 默认不是幂等性的，但是我们可以创建幂等性 Producer。<code>enable.idempotence</code> 设置为 True，即可保证 Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要更改。配置后，Kafka 自动做消息的去重操作。</p><p>其实，底层原理非常简单，就是经典的以空间换时间的做法，Broker 多保存一些字段，当 Producer 发送消息请求的时候，Broker 能够判断消息是否重复，进而再丢弃掉重复消息。</p><h2 id="「幂等性-Producer-的作用范围」"><a href="#「幂等性-Producer-的作用范围」" class="headerlink" title="「幂等性 Producer 的作用范围」"></a>「幂等性 Producer 的作用范围」</h2><ul><li><p>幂等性只能保证单个分区上的幂等性，无法实现多分区幂等性。</p></li><li><p>幂等性针对单个会话的幂等性，不会实现跨会话的幂等性。</p></li></ul><blockquote><p>这里的会话，可以理解成 Producer 进程的一次运行，当重启了 Producer 进程之后，这种幂等性就丧失了。</p></blockquote><h1 id="十六、事务"><a href="#十六、事务" class="headerlink" title="十六、事务"></a>十六、事务</h1><p>Kafka 自从 0.11 版本就开始支持事务，目前主要是在 read committed 隔离级别上做事务。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。</p><h2 id="「事务型-Producer」"><a href="#「事务型-Producer」" class="headerlink" title="「事务型 Producer」"></a>「事务型 Producer」</h2><p>事物型 Producer 能够保证将消息原子性的写入到多个分区中。这批消息要么全部成功，要么全部失败，另外，事务型 Producer 也不怕进程的重启。当 Producer 重启之后，Kafka 仍能保证它们发送消息的精确一次处理。</p><p>设置事务型 Producer 的方式也比较简单，满足两个设置即可：</p><ul><li><p>和幂等性 Producer 一样，开启 <code>enable.idempotence = true</code>。</p></li><li><p>设置 Producer 端参数 <code>transactional.id</code>，最好设置一个有意义的名字。</p></li></ul><p>此外，还需要在 Producer 代码中做一些调整，如这段代码所示：</p><pre><code class="language-java">producer.initTransactions();  try &#123;              producer.beginTransaction();              producer.send(record1);              producer.send(record2);              producer.commitTransaction();  &#125; catch (KafkaException e) &#123;              producer.abortTransaction();  &#125;</code></pre><p>和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。</p><p>实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。</p><p>有一个 <code>isolation.level</code> 参数，这个参数有两个取值：</p><ol><li><p><code>read_uncommitted</code>：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。</p></li><li><p><code>read_committed</code>：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息</p></li></ol><h1 id="十七、拦截器"><a href="#十七、拦截器" class="headerlink" title="十七、拦截器"></a>十七、拦截器</h1><p><strong>Kafka 拦截器分为生产者拦截器和消费者拦截器。</strong> 生产者拦截器允许你在发送消息前以及消息提交成功之后植入拦截器逻辑。而消费者拦截器支持消费消息前以及提交位移后编写特定逻辑。可以将一组懒啊节气串联成一个大的拦截器，Kafka 会按照顺序依次执行拦截器逻辑。</p><p>当前 Kafka 拦截器是通过参数配置完成，生产者和消费者两端都有个相同的参数 <code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p><pre><code class="language-java">Properties props = new Properties();   List interceptors = new ArrayList&lt;&gt;();   interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1   interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2   props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</code></pre><p>怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？</p><p>这两个类以及所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code> 接口。</p><p>该接口是 Kafka 提供的，里面有两个核心方法：</p><ol><li><p>onSend：该方法在消息发送前被调用。</p></li><li><p>onAcknowledgement：该方法在消息成功提交或者提交失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 方法不在同一个线程中调用，因此如果在这两个方法中调用了共享可变变量，一定要注意线程安全问题。</p></li></ol><p>同理，消费者拦截器也是同样的方法，都要继承 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里也有两个核心方法。</p><ol><li><p>onConsuume：该方法在消息返回给 Consumer 程序之前调用。</p></li><li><p>onCommit：Consumer 在提交位移之后调用该方法。通常做法是在该方法中做一些记账的动作，例如打印日志等。</p></li></ol><h1 id="十八、控制器（Controller）"><a href="#十八、控制器（Controller）" class="headerlink" title="十八、控制器（Controller）"></a>十八、控制器（Controller）</h1><p><strong>控制器组件（controller），主要是用于在 Apache Zookeeper 的帮助下管理和协调整个 Kafka 集群。</strong></p><p>集群中任意一台 Broker 都可以成为控制器角色。在 Kafka 集群启动的时候，第一个在 Zookeeper 中创建&#x2F;controller 节点的 Broker 会被指定为控制器。</p><p>控制器主要的功能如下：</p><ol><li><strong>主题管理（创建，删除，增加分区）</strong></li></ol><p>控制器帮我们完成对 Kafka 主题的创建，删除以及分区增加的操作。</p><ol start="2"><li><p><strong>分区重分配</strong></p></li><li><p><strong>Preferred 领导者选举</strong></p></li></ol><p>Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。</p><ol start="4"><li><strong>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</strong></li></ol><p>在 Zookeeper 对 Kafka 协助管理工程中，<strong>「Watch 机制」</strong> 和 <strong>「临时节点」</strong> 是两个重要的机制。 </p><p>Broker 的创建时候，Zookeeper 会在 Zookeeper 的 &#x2F;broker&#x2F;ids 下创建专属的 znode 节点，这个节点就是临时节点。一旦节点创建完成，ZooKeeper 就会通过 Watch 机制将消息通知推送给控制器，只要，控制器就能自动感知这个变化，进而开启后续的新增 Broker 作业。</p><p>当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。</p><p>同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。</p><ol start="5"><li><strong>数据服务</strong></li></ol><p>控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</p><h2 id="「控制器故障转移（Failover）」"><a href="#「控制器故障转移（Failover）」" class="headerlink" title="「控制器故障转移（Failover）」"></a>「控制器故障转移（Failover）」</h2><p><strong>「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」</strong>。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。</p><p><img src="/img/5711d6da84f2000a181c356e080deec4_MD5.png" alt="[5711d6da84f2000a181c356e080deec4_MD5.png]"></p><p>最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了<code>/controller</code>临时节点。</p><p>之后，所有存活的Broker开始竞选新的控制器身份。Broker 3最终赢得了选举，成功地在ZooKeeper上重建了 <code>/controller</code> 节点。之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。</p><p>至此，控制器的Failover完成，可以行使正常的工作职责了。</p><h1 id="二十、日志存储"><a href="#二十、日志存储" class="headerlink" title="二十、日志存储"></a>二十、日志存储</h1><p>Kafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。</p><p>每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。</p><p>但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。</p><p>下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。</p><p><img src="/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png" alt="[4cc119f98ed02df15c264d1cf428d32b_MD5.png]"></p><p><strong>「LogSegment」</strong></p><p>在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。</p><p>其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的 <code>config/server.properties</code> 配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。</p><p><img src="/img/5c376d6d6186292ebc461285ce0ac879_MD5.png" alt="[5c376d6d6186292ebc461285ce0ac879_MD5.png]"></p><h1 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h1><p><strong>「broker端配置」</strong></p><ul><li><code>broker.id</code></li></ul><p>每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 <code>broker.id</code>，它的默认值是 0。</p><p>这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，</p><ul><li><code>port</code></li></ul><p>如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。</p><p>要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。</p><ul><li><code>zookeeper.connect</code></li></ul><p>用于保存 broker 元数据的 Zookeeper 地址是通过 <code>zookeeper.connect</code> 来指定的。</p><p>比如可以这么指定 <code>localhost:2181</code> 表示这个 Zookeeper 是运行在本地 2181 端口上的。</p><p>我们也可以通过 比如我们可以通过 <code>zk1:2181,zk2:2181,zk3:2181</code> 来指定 <code>zookeeper.connect</code> 的多个参数值。</p><p>该配置参数是用冒号分割的一组 <code>hostname:port/path</code> 列表，其含义如下</p><ul><li><p>hostname 是 Zookeeper 服务器的机器名或者 ip 地址。</p></li><li><p>port 是 Zookeeper 客户端的端口号</p></li><li><p>&#x2F;path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 <code>chroot</code> 环境，如果不指定默认使用跟路径。</p></li></ul><blockquote><p>❝<br>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的<code>zookeeper.connect</code>参数可以这样指定：<code>zk1:2181,zk2:2181,zk3:2181/kafka1</code>和<code>zk1:2181,zk2:2181,zk3:2181/kafka2</code><br>❞</p></blockquote><ul><li><code>log.dirs</code></li></ul><p>Kafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 <code>log.dirs</code> 来制定的，它是用一组逗号来分割的本地系统路径，<code>log.dirs</code> 是没有默认值的，<strong>「你必须手动指定他的默认值」</strong>。</p><p>其实还有一个参数是 <code>log.dir</code>，这个配置是没有 <code>s</code> 的，默认情况下只用配置 <code>log.dirs</code> 就好了，比如你可以通过 <code>/home/kafka1,/home/kafka2,/home/kafka3</code> 这样来配置这个参数的值。</p><ul><li><code>auto.create.topics.enable</code></li></ul><p>默认情况下，kafka 会自动创建主题</p><p><code>auto.create.topics.enable</code>参数建议最好设置成 false，即不允许自动创建 Topic。</p><p><strong>「主题相关配置」</strong></p><ul><li><code>num.partitions</code></li></ul><p>num.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。</p><ul><li><code>default.replication.factor</code></li></ul><p>这个参数比较简单，它表示 kafka保存消息的副本数。</p><ul><li><code>log.retention.ms</code></li></ul><p>Kafka 常根据时间来决定数据可以保留多久。</p><p>默认使用<code>log.retention.hours</code>参数来配置时间，默认是 168 个小时，也就是一周。</p><p>除此之外，还有两个参数<code>log.retention.minutes</code> 和<code>log.retentiion.ms</code> 。</p><p>这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用<code>log.retention.ms</code>。</p><ul><li><code>message.max.bytes</code></li></ul><p>broker 通过设置 <code>message.max.bytes</code> 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。</p><ul><li><code>retention.ms</code></li></ul><p>规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。</p><h1 id="消息丢失问题"><a href="#消息丢失问题" class="headerlink" title="消息丢失问题"></a>消息丢失问题</h1><h2 id="「生产者程序丢失数据」"><a href="#「生产者程序丢失数据」" class="headerlink" title="「生产者程序丢失数据」"></a><strong>「生产者程序丢失数据」</strong></h2><p>目前Kafka Producer是异步发送消息的，也就是说如果你调用的是<code>producer.send(msg)</code>这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。</p><p><strong>如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？</strong></p><p>其实原因有很多：</p><ol><li>例如网络抖动，导致消息压根就没有发送到Broker端；</li></ol><p>如果是网络抖动导致的失败，可以通过 Producer 中的参数 <code>retries</code> (重试次数)设置比较合理的值来解决，一般来说为 3。同时，建议还要设置重试间隔 <code>retry.backoff.ms</code> 来避免 3 次重试间隔太短导致多次失败。</p><ol start="2"><li>或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。</li></ol><p>实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>。在 SpringBoot 中可以用类似的方式来处理：</p><pre><code class="language-java">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(smsBusiPrediction, msg);  future.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() &#123;     @Override     public void onSuccess(SendResult&lt;String, Object&gt; result) &#123;        log.info(&quot;=====向kafka推送信息成功=====&quot;);     &#125;     @Override     public void onFailure(Throwable ex) &#123;        log.info(&quot;=====向kafka推送信息失败！！=====&quot;,ex);     &#125;   &#125;);</code></pre><p>它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p><h2 id="「消费者程序丢失数据」"><a href="#「消费者程序丢失数据」" class="headerlink" title="「消费者程序丢失数据」"></a><strong>「消费者程序丢失数据」</strong></h2><p>Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。</p><p>下面这张图它清晰地展示了Consumer端的位移数据。</p><p><img src="/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png" alt="[adc9951c2edb1fba60deea2d87fb2d44_MD5.png]"></p><p>比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。</p><p>假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。这里的关键在于Consumer自动提交位移。这个问题的解决方案也很简单：<strong>「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」</strong>。</p><h2 id="「Kafka-内部出现消息丢失」"><a href="#「Kafka-内部出现消息丢失」" class="headerlink" title="「Kafka 内部出现消息丢失」"></a><strong>「Kafka 内部出现消息丢失」</strong></h2><p>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</p><p><strong>设置 <code>acks = all</code></strong></p><p>解决办法就是我们设置 <code>acks = all</code>。<code>acks</code> 是 Kafka 生产者(Producer) 很重要的一个参数。</p><p>acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 <strong>acks &#x3D; all</strong> 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.</p><p><strong>设置 <code>replication.factor &gt;= 3</code></strong></p><p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <code>replication.factor &gt;= 3</code>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p><p><strong>设置 <code>min.insync.replicas &gt; 1</code></strong></p><p>一般情况下我们还需要设置 <strong><code>min.insync.replicas&gt; 1</code></strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p><p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong><code>replication.factor &gt; min.insync.replicas</code></strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong><code>replication.factor = min.insync.replicas + 1</code></strong>。</p><p><strong>设置 <code>unclean.leader.election.enable = false</code></strong></p><blockquote><p><strong>Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false</strong></p></blockquote><p>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong><code>unclean.leader.election.enable = false</code></strong> 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</p><h2 id="「最佳实践」"><a href="#「最佳实践」" class="headerlink" title="「最佳实践」"></a>「最佳实践」</h2><p>总结Kafka 避免消息丢失的配置：</p><ol><li><p>在 Producer 端：</p><ul><li><p>不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>，一定要使用带有回调通知的 send 方法。</p></li><li><p>设置 <code>retries</code>  为一个较大的值。这里的<code>retries</code>同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</p></li><li><p>设置 <code>acks = all</code>，acks 是 Producer 的一个参数，代表了你对已提交消息的定义，如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交。</p></li></ul></li><li><p>在 Consumer 端：</p><ul><li>确保消息消费完成再提交，Consumer端有个参数 <code>enable.auto.commit</code>，最好把它设置成 false，并采用手动提交位移的方式。</li></ul></li><li><p>在 Kafka 内部：</p><ul><li><p>设置 <code>unclean.leader.election.enable = false</code>，这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失，故一般都要将该参数设置成 false，即不允许这种情况的发生。</p></li><li><p>设置 <code>replication.factor &gt;= 3</code>，这也是 Broker 端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。</p></li><li><p>设置 <code>min.insync.replicas &gt; 1</code>，这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于 1 可以提升消息持久性，在实际环境中千万不要使用默认值 1。</p></li><li><p>确保 <code>replication.factor &gt; min.insync.replicas</code>，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</p></li></ul></li></ol><h1 id="重复消费问题"><a href="#重复消费问题" class="headerlink" title="重复消费问题"></a>重复消费问题</h1><p><strong>「消费重复的场景」</strong></p><p>在 <code>enable.auto.commit</code> 默认值true情况下，出现重复消费的场景有以下几种：</p><blockquote><p>❝<br>consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。<br>❞</p></blockquote><p>例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。</p><p>下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。</p><p>解决方案：在发生异常时正确处理未提交的offset</p><p><strong>「消费者消费时间过长」</strong></p><p><code>max.poll.interval.ms</code>参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。</p><p>举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于<code>max.poll.interval.ms</code>  默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。</p><p>在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。</p><p><strong>「解决方案：」</strong></p><p>1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲<code>max.poll.interval.ms</code>值设置大一点，避免不必要的rebalance；可适当减小<code>max.poll.records</code>的值，默认值是500，可根据实际消息速率适当调小。</p><p>2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。</p><h1 id="消息顺序问题"><a href="#消息顺序问题" class="headerlink" title="消息顺序问题"></a>消息顺序问题</h1><p>我们都知道 <code>kafka</code> 的 <code>topic</code> 是无序的，但是一个 <code>topic</code> 包含多个 <code>partition</code>，每个 <code>partition</code> 内部是有序的（分区内采用尾插法）</p><p><img src="/img/466a6f44f4b183a6bae184c90378b300_MD5.png" alt="[466a6f44f4b183a6bae184c90378b300_MD5.png]"></p><p><strong>「乱序场景1」</strong></p><p>因为一个topic可以有多个partition，kafka只能保证partition内部有序</p><p><strong>「解决方案」</strong></p><p>1、可以设置topic，有且只有一个partition，<strong>不推荐，这样就违背了 Kafka 的设计初衷，即多分区，多副本的概念。</strong></p><p>2、<strong>（推荐）</strong> 根据业务需要，需要顺序的指定为同一个partition，在 Broker 提交的时候，规定 topic，partition，key，data 四个参数统一。</p><p><strong>「乱序场景2」</strong></p><p>对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序</p><p><strong>「解决方案」</strong></p><p>消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作</p><p><img src="/img/bb94c4025a04733be2eb858d968eaffd_MD5.png" alt="[bb94c4025a04733be2eb858d968eaffd_MD5.png]"></p><p><strong>「通过设置相同key来保证消息有序性，会有一点缺陷：」</strong></p><p>例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数 <code>max.in.flight.requests.per.connection=1</code>，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5</p><h1 id="高性能原因"><a href="#高性能原因" class="headerlink" title="高性能原因"></a>高性能原因</h1><h2 id="「顺序读写」"><a href="#「顺序读写」" class="headerlink" title="「顺序读写」"></a><strong>「顺序读写」</strong></h2><p>kafka的消息是不断追加到文件中的，这个特性使<code>kafka</code>可以充分利用磁盘的顺序读写性能</p><p>顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p><p>Kafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时</p><h2 id="「零拷贝」"><a href="#「零拷贝」" class="headerlink" title="「零拷贝」"></a><strong>「零拷贝」</strong></h2><p>传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区</p><p>这个过程中发生了多次数据拷贝</p><p>为了减少不必要的拷贝，<code>Kafka</code> 依赖 Linux 内核提供的 <code>Sendfile</code> 系统调用</p><p>在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝</p><p>在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 <code>Sendfile</code> 方法发送文件，减少了上下文切换，因此大大提高了性能</p><h2 id="「MMAP技术」"><a href="#「MMAP技术」" class="headerlink" title="「MMAP技术」"></a><strong>「MMAP技术」</strong></h2><p>除了 <code>Sendfile</code> 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files</p><p>Kafka 使用 <code>Memory Mapped Files</code> 完成内存映射，<code>Memory Mapped Files</code> 对文件的操作不是 <code>write/read</code>，而是直接对内存地址的操作，如果是调用文件的 <code>read</code> 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 <code>MMAP</code>可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销</p><p>Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入</p><p>Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。</p><h2 id="「批量发送读取」"><a href="#「批量发送读取」" class="headerlink" title="「批量发送读取」"></a><strong>「批量发送读取」</strong></h2><p>Kafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送</p><p>同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度</p><h2 id="「数据压缩」"><a href="#「数据压缩」" class="headerlink" title="「数据压缩」"></a><strong>「数据压缩」</strong></h2><p>Kafka还支持对消息集合进行压缩，<code>Producer</code>可以通过<code>GZIP</code>或<code>Snappy</code>格式对消息集合进行压缩</p><p>压缩的好处就是减少传输的数据量，减轻对网络传输的压力</p><p>Producer压缩之后，在<code>Consumer</code>需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得</p><h2 id="「分区机制」"><a href="#「分区机制」" class="headerlink" title="「分区机制」"></a><strong>「分区机制」</strong></h2><p>kafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加 <code>并行操作</code> 的能力</p><h1 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h1><h2 id="「Kafka是Push还是Pull模式？」"><a href="#「Kafka是Push还是Pull模式？」" class="headerlink" title="「Kafka是Push还是Pull模式？」"></a><strong>「Kafka是Push还是Pull模式？」</strong></h2><p>Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。</p><p>在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。</p><p>push模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。</p><p>消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。</p><blockquote><p>❝<br>Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。<br>❞</p></blockquote><p>Pull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。</p><p>Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。</p><h2 id="「Kafka如何保证高可用-」"><a href="#「Kafka如何保证高可用-」" class="headerlink" title="「Kafka如何保证高可用?」"></a><strong>「Kafka如何保证高可用?」</strong></h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&mid=2247484980&idx=1&sn=6e0c7112dd72d0edc284009e7503b2ac&scene=21#wechat_redirect">面试题：Kafka如何保证高可用？有图有真相</a></p><h2 id="「Kafk的使用场景」"><a href="#「Kafk的使用场景」" class="headerlink" title="「Kafk的使用场景」"></a><strong>「Kafk的使用场景」</strong></h2><p>业界Kafka实际应用场景</p><blockquote><p>❝<br>异步通信<br>❞</p></blockquote><p>消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。</p><blockquote><p>❝<br>日志同步<br>❞</p></blockquote><p>大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。</p><p>为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。</p><blockquote><p>❝<br>实时计算<br>❞</p></blockquote><p>随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。</p><p>很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。</p><p>实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。</p><h2 id="「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」"><a href="#「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」" class="headerlink" title="「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」"></a><strong>「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」</strong></h2><ol><li><p>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</p></li><li><p>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</p></li></ol><p>参考资料：</p><blockquote><p> <a href="https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html">Kafka常见问题总结</a></p><p> <a href="https://mp.weixin.qq.com/s/zfHoSsuSpXWOaxQrm7uvkA">Kafka核心知识总结！</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Kafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据&lt;/p&gt;
&lt;h1 id=&quot;一、基本概念&quot;&gt;&lt;a href=&quot;#一、基本概念&quot; class=&quot;</summary>
      
    
    
    
    <category term="中间件" scheme="https://www.lazydaily.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="https://www.lazydaily.cn/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>聊聊Java IO的那些事</title>
    <link href="https://www.lazydaily.cn/761386768996841/"/>
    <id>https://www.lazydaily.cn/761386768996841/</id>
    <published>2024-11-30T16:00:00.000Z</published>
    <updated>2025-05-20T07:21:35.911Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th align="center"></th><th align="center">BIO</th><th align="center">NIO</th><th align="center">AIO</th></tr></thead><tbody><tr><td align="center">IO模型</td><td align="center">同步阻塞</td><td align="center">同步非阻塞（多路复用）</td><td align="center">异步非阻塞</td></tr><tr><td align="center">编程难度</td><td align="center">简单</td><td align="center">复杂</td><td align="center">复杂</td></tr><tr><td align="center">可靠性</td><td align="center">差</td><td align="center">好</td><td align="center">好</td></tr><tr><td align="center">吞吐量</td><td align="center">低</td><td align="center">高</td><td align="center">高</td></tr></tbody></table><h1 id="阅前须知"><a href="#阅前须知" class="headerlink" title="阅前须知"></a>阅前须知</h1><p><code>阻塞 IO</code> 和 <code>非阻塞 IO</code></p><p>这两个概念是 <code>程序级别</code> 的。主要描述是程序请求操作系统 IO 操作之后，如果 IO 资源没有准备好，那么程序如何处理问题：前者等待，后者继续执行（并且使用线程一直轮询，直到有 IO 资源准备好）</p><p><code>同步 IO </code> 和 <code>非同步IO</code></p><p>这两个概念是<code>操作系统级别</code>的。主要描述的是操作系统在收到程序请求 IO 操作后，如果 IO 资源没有准备好，该如何相应程序的问题：前者不响应，后者返回一个标记，当 IO 资源准备好之后，在用事件机制返回给程序。</p><h1 id="一、BIO（Blocking-I-O）"><a href="#一、BIO（Blocking-I-O）" class="headerlink" title="一、BIO（Blocking I&#x2F;O）"></a>一、BIO（Blocking I&#x2F;O）</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>Java BIO：同步并阻塞（传统阻塞性），应用程序中进程在发起 IO 调用后至内核执行 IO 操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次 IO 操作为阻塞 IO。阻塞 IO 简称 BIO，Blocking IO。</p><p>以前大多数网络通信方式都是阻塞模式，即：</p><ul><li>客户端向服务器端发送请求后，客户端会一直等待（不会再做其他事情），直到服务器端返回结果或者网络出现问题。</li><li>服务端同样的，当在处理某个客户端 A 发来的请求是，另一个客户端 B 发来的请求会等待，直到服务器端的这个处理线程完成上个处理。</li></ul><p> <img src="/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png" alt="[]"></p><h2 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h2><ol><li>服务器启动一个 ServerSocket。</li><li>客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。</li><li>客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。</li><li>如果有响应，客户端线程会等待请求结束后，再继续执行。</li></ol><pre><code class="language-java">package com.atguigu.bio;import java.io.InputStream;import java.net.ServerSocket;import java.net.Socket;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class BIOServer &#123;        public static void main(String[] args) throws Exception &#123;        //线程池机制        //思路        //1. 创建一个线程池        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();        //创建ServerSocket        ServerSocket serverSocket = new ServerSocket(6666);        System.out.println(&quot;服务器启动了&quot;);        while (true) &#123;            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());            //监听，等待客户端连接            System.out.println(&quot;等待连接....&quot;);            //会阻塞在accept()            final Socket socket = serverSocket.accept();            System.out.println(&quot;连接到一个客户端&quot;);            //就创建一个线程，与之通讯(单独写一个方法)            newCachedThreadPool.execute(new Runnable() &#123;                public void run() &#123;//我们重写                    //可以和客户端通讯                    handler(socket);                &#125;            &#125;);        &#125;     &#125;        //编写一个handler方法，和客户端通讯    public static void handler(Socket socket) &#123;        try &#123;            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());            byte[] bytes = new byte[1024];            //通过socket获取输入流            InputStream inputStream = socket.getInputStream();            //循环的读取客户端发送的数据            while (true) &#123;                System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());                System.out.println(&quot;read....&quot;);                int read = inputStream.read(bytes);                if (read != -1) &#123;                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据                &#125; else &#123;                    break;                &#125;            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            System.out.println(&quot;关闭和client的连接&quot;);            try &#123;                socket.close();            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;</code></pre><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>传统的 IO 模型，其主要是一个 Server 对接 N 个客户端，在客户端连接之后，为每个客户端分配一个子线程。如图所示：</p><p> <img src="/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png" alt="[]"></p><p>从图中可以看出，传统 IO 的特点在于：</p><ul><li>每个客户端连接到达时，服务端会分配一个线程给该客户端，该线程处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程</li><li>同一时刻，服务端的吞吐量与服务器所提供的线程数量呈线性关系的。</li></ul><p>如果并发量不大，运行没有问题，但是如果海量并发时候，就会出现问题：</p><ol><li>每次请求都要创建独立的线程，与对应的客户端进行数据的Read，业务处理，数据Write、</li><li>当并发数较大时，需要创建大量线程处理连接，资源占用较大。</li><li>连接建立后，如果当前线程展示没有数据可读，则线程就阻塞在Read操作上，造成线程资源浪费。</li></ol><h2 id="改进：多线程方式-伪异步方式"><a href="#改进：多线程方式-伪异步方式" class="headerlink" title="改进：多线程方式 - 伪异步方式"></a>改进：多线程方式 - 伪异步方式</h2><p>上述说的情况只是服务器只有一个线程的情况，那么如果引入多线程是不是可以解决这个问题：</p><ul><li>当服务器收到客户端 X 的请求后，（读取到所有的请求数据后）将这个请求送入到一个独立线程进行处理，然后主线程继续接收客户端 Y 的请求。</li><li>客户端侧，也可以用一个子线程和服务器端进行通信。这样客户端主线程的其他工作不受影响，当服务器有响应信息时候再有这个子线程通过 <code>监听模式/观察模式</code>（等其他设计模式）通知主线程。</li></ul><p> <img src="/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png" alt="[]"></p><p>但是多线程解决这个问题有局限性：</p><ul><li>操作系统通知accept() 的方式还是单个，即：服务器收到数据报文之后的“业务处理过程”可以多线程，但是报文的接收还是需要一个个来</li><li>在操作系统中，线程是有限的。线程越多，CPU 切换所需时间也越长，用来处理真正业务的需求也就越少。</li><li>创建线程需要较大的资源消耗。JVM 创建一个线程，即使不进行任何工作，也需要分配一个堆栈空间（128k）。</li><li>如果程序中使用了大量的长连接，线程是不会关闭的，资源消耗更容易失控。</li></ul><blockquote><p>为啥 <code>serverSocket. accept()</code> 会出现阻塞？</p></blockquote><p>是因为 Java 通过 JNI 调用的系统层面的 <code>accept0()</code> 方法，<code>accept0()</code> 规定如果发现套间字从指定的端口来，就会等待。其实就是内部实现是操作系统级别的同步 IO。</p><h1 id="二、NIO（non-Blocking-I-O）"><a href="#二、NIO（non-Blocking-I-O）" class="headerlink" title="二、NIO（non-Blocking I&#x2F;O）"></a>二、NIO（non-Blocking I&#x2F;O）</h1><p>了解 NIO 之前我们先来看看标准 I&#x2F;O（Standard I&#x2F;O）。</p><p>Standard I&#x2F;O 是对字节的读写，在进行 I&#x2F;O 之前，首先创建一个流对象，流对象的读写操作都是按字节，一个字节一个字节的读或者写。而 NIO 把 I&#x2F;O 抽象成块，类似磁盘的读写，每次 I&#x2F;O 操作的单位都是一个块，块被读入内存之后就是一个 <code> byte[]</code>，NIO 一次可以读或者写多个字节。</p><h2 id="流和块"><a href="#流和块" class="headerlink" title="流和块"></a>流和块</h2><p>IO 和 NIO 最重要的区别就是对数据的打包和传输的方式，IO 是以流的方式处理数据，而 NIO 以块的方式处理数据。</p><p>面向流的 IO 一次性处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 IO 通常处理非常慢。</p><p>面向块的 I&#x2F;O 一次性处理一个数据块：按块处理数据比按流处理数据要快的多，但是面向块的 I&#x2F;O 确实一些面向流的 I&#x2F;O 所具有的优雅和简单。</p><p>I&#x2F;O 包和 NIO 已经很好的集成了，<code>java.io.*</code> 中已经以 NIO 重新实现了，可以利用一些 NIO 的特性。例如：在 <code>java.io.*</code> 中某些类包含以块的形式读写数据的操作，这使得及时在面向流的系统中，处理数据也会更快。</p><h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><p>Java NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮训到连接有 I&#x2F;O 请求就进行处理。</p><p><strong>核心概念：</strong></p><ol><li><strong>三大核心：</strong> Channel（通道）、Buffer（缓冲区）、Selector（选择器）。</li><li><strong>面向缓冲区，或者是面向块编程。</strong> 数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩弹性网络。</li><li><strong>非阻塞模式</strong>， 使一个线程从某个通道发送请求或者读取数据，但是他仅能得到目前可用的数据，如果目前没有数据可用，就什么都不会获取，而不是保持线程阻塞。所以知道数据变得可读取之前，该线程还可以去做其他实行。</li><li><strong>Channel 和 Buffer 一一对应。</strong></li><li><strong>一个线程只有一个 Selector，一个线程对应对个 Channel（连接）</strong>。</li><li>程序切换到哪个 Channel 是由事件决定，Event 就是个重要概念。</li><li>Selector 会根据不同的事件，在各个通道上切换。</li><li><strong>Buffer 是一个内存块，底层就是一个数组</strong>。</li><li>数据读写都是通过 Buffer，区别于 BIO 的输入输出流，且<strong>双向</strong>，需要 <code>flip</code> 方法切换 <code>Channel</code> 是双向的 。</li></ol><h2 id="编程原理"><a href="#编程原理" class="headerlink" title="编程原理"></a>编程原理</h2><ol><li>当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。</li><li>Selector 进行监听 select 方法，返回有事件发生的通道个数。</li><li>将 SocketChannel 注册到 Selector 上（<code>register(Selector selector, int ops)</code>），一个 Selector 可以注册多个 SocketChannel。</li><li>注册后返回 SelectionKey，会和该 Selector 关联（集合）。</li><li>当有事件发生时，进一步得到各个 SelectionKey。</li><li>通过channel () 方法，用 SelectionKey 反向获取 SocketChannel。</li><li>可以通过得到的 channel，完成业务处理。</li></ol><h2 id="1-缓冲区（Buffer）"><a href="#1-缓冲区（Buffer）" class="headerlink" title="1. 缓冲区（Buffer）"></a>1. 缓冲区（Buffer）</h2><h3 id="Buffer-类及其子类"><a href="#Buffer-类及其子类" class="headerlink" title="Buffer 类及其子类"></a>Buffer 类及其子类</h3><p><code>ByteBuffer</code> 字节数据；<code>ShortBuffer</code> 字符串数据；<code>CharBuffer</code> 字符数据；<code>IntBuffer</code> 整数；<code>LongBuffer</code> 长整数；<code>DoubleBuffer</code> 小数；<code>FloatBuffer</code> 小数</p><h3 id="Buffer-属性和方法"><a href="#Buffer-属性和方法" class="headerlink" title="Buffer 属性和方法"></a>Buffer 属性和方法</h3><p>Buffer 类提供了 4 个属性来提供数据元素信息：<code>capacity（容量）</code>：缓存区的最大容量，<code>Limit（终点）</code>：缓存区最大可操作位置，<code>Position（位置）</code> ：缓存区当前在操作的位置，<code>Mark（标记）</code>：标记位置</p><pre><code class="language-java">public abstract class Buffer&#123;public final int capacity();public final int position();public final Buffer position(int newPosition);public final int limit();public final Buffer limit(int newLimit);&#125;//其中比较常用的就是ByteBuffer（二进制数据），该类主要有以下方法public abstract class ByteBuffer()&#123;public static ByteBuffer allocateDirect(int capacity);//直接创建缓冲区public static ByteBuffer allocate(int capacity);//设置缓冲区的初始容量public static ByteBuffer wrap(byte[] array);//把一个数组放入到缓冲区使用//构造初始化位置offset和上界length的缓冲区public static ByteBuffer wrap(byte[] array,int offset,int length);//缓冲区读取相关APIpublic abstract byte get();//从当前位置position上get，get之后，positon会+1public abstract byte get(int index);//从绝对位置获取public abstract ByteBuffer put(byte b);//当前位置上put，put之后，position会+1public abstract ByteBuffer put(int index,byte b);//从绝对位置put&#125;</code></pre><p>状态变量的改变过程举例:</p><p>① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit &#x3D; capacity &#x3D; 8。capacity 变量不会改变，下面的讨论会忽略它。</p><p> <img src="/img/a8f0d4502adb087892e11866bdac7d57_MD5.png" alt="[]"></p><p>② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。</p><p> <img src="/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png" alt="[]"></p><p>③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。</p><p> <img src="/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png" alt="[]"></p><p>④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。</p><p> <img src="/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png" alt="[]"></p><p>⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。</p><p> <img src="/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png" alt="[]"></p><h3 id="文件-NIO-实例"><a href="#文件-NIO-实例" class="headerlink" title="文件 NIO 实例"></a>文件 NIO 实例</h3><p>以下展示了使用 NIO 快速复制文件的实例：</p><pre><code class="language-java">public static void fastCopy(String src, String dist) throws IOException &#123;    /* 获得源文件的输入字节流 */    FileInputStream fin = new FileInputStream(src);    /* 获取输入字节流的文件通道 */    FileChannel fcin = fin.getChannel();    /* 获取目标文件的输出字节流 */    FileOutputStream fout = new FileOutputStream(dist);    /* 获取输出字节流的通道 */    FileChannel fcout = fout.getChannel();    /* 为缓冲区分配 1024 个字节 */    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);    while (true) &#123;        /* 从输入通道中读取数据到缓冲区中 */        int r = fcin.read(buffer);        /* read() 返回 -1 表示 EOF */        if (r == -1) &#123;            break;        &#125;        /* 切换读写 */        buffer.flip();        /* 把缓冲区的内容写入输出文件中 */        fcout.write(buffer);                /* 清空缓冲区 */        buffer.clear();    &#125;&#125;</code></pre><h2 id="2-通道（Channel）"><a href="#2-通道（Channel）" class="headerlink" title="2. 通道（Channel）"></a>2. 通道（Channel）</h2><p>通道类似流，但是有如下区别：</p><ul><li>通道可以同时读写，而流只能读或写</li><li>通道可以实现异步读写数据</li><li>通道可以从缓冲区读数据，也可以写数据到缓冲区</li></ul><h3 id="通道分类"><a href="#通道分类" class="headerlink" title="通道分类"></a>通道分类</h3><p>Channel 在 NIO 中是一个接口 <code>public interface Channle extends Closeable&#123;&#125;</code>。其中，常用的 Channel 类有：</p><ol><li><code>FileChannel</code>：用于文件的数据读写；</li><li><code>DatagramChannel</code>：用于 UDP 的数据读写；</li><li><code>ServerSocketChannel</code>：可以监听新来的连接，对每一个新进来的连接都会创建一个 SocketChannel。只有通过这个通道，应用程序才能箱操作系统注册支持“多路复用 IO”的端口减轻。支持 TCP 和 UDP 协议；</li><li><code>SocketChannel</code>：TCP Socket 套接字的监听通道，用于 TCP 的数据读写</li><li>其他的通道包括：</li></ol><p> <img src="/img/94530647a3be7da4d2de055fff8bacaf_MD5.png" alt="[]"></p><h3 id="FileChannel-类"><a href="#FileChannel-类" class="headerlink" title="FileChannel 类"></a>FileChannel 类</h3><p>对本地文件进行 IO 操作，常用方法及实例应用：</p><pre><code class="language-java">//从通道读取数据并放到缓冲区内public int read(ByteBuffer content);//从缓冲区写数据到通道中public int write(ByteBuffer content);//从目标通道中复制数据到当前通道内public long transferFrom(ReadableByteChannel src,long position,long count);//把数据从当前通道复制到目标通道public long transferTo(long position,long count,WritabelByteChannel target);</code></pre><p>1 . 写入文件，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p><pre><code class="language-java">//使用之前ByteBuffer和FileChannel类，写入文件import java.io.FileOutputStream;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class NIOFileChannel&#123;public static void main(String[] args) throws Exception&#123;String str = &quot;hello,world&quot;;//创一个输出流 -&gt; channelFileOutputStream stream = new FileOutputStream(&quot;d:\\file.txt&quot;);//通过 stream 获取对应的 FileChannel//这个 fileChannel 真实类型是 FileChannelImplFileChannel fileChannel = stream.getChannel();//创建一个缓冲区 ByteBufferByteBuffer byteBuffer = ByteBuffer.allocate(1024);//将 str 放入到缓冲区byteBuffer.put(str.getBytes());//对 byteBuffer 进行 flipbyteBuffer.flip();//将 byteBuffer 写入到 fileChannelfileChannel.write(byteBuffer);fileOutputStream.close();&#125;&#125;</code></pre><p>2 . 读取文件数据并展示，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p><pre><code class="language-java">//读取本地文件import java.io.FileOutputStream;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class NIOFileChannel&#123;public static void main(String[] args) throws Exception&#123;//创一个输出流 -&gt; channelFile file = new File(&quot;d:\\file.txt&quot;);FileOutputStream stream = new FileOutputStream(file);//通过 stream 获取对应的 FileChannel//这个 fileChannel 真实类型是 FileChannelImplFileChannel fileChannel = stream.getChannel();//创建一个缓冲区 ByteBufferByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());//将 byteBuffer 写入到 fileChannelfileChannel.read(byteBuffer);//将 byteBuffer的字节转化成StringSystem.out.println(new String(byteBuffer.array()));fileOutputStream.close();&#125;&#125;</code></pre><p>3 . 使用一个 <code>Buffer</code> 完成文件的读取、写入</p><pre><code class="language-java">import java.io.FileInputStream;import java.io.FileOutputStream;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class NIOFileChannel03 &#123;    public static void main(String[] args) throws Exception &#123;        FileInputStream fileInputStream = new FileInputStream(&quot;1.txt&quot;);        FileChannel fileChannel01 = fileInputStream.getChannel();        FileOutputStream fileOutputStream = new FileOutputStream(&quot;2.txt&quot;);        FileChannel fileChannel02 = fileOutputStream.getChannel();        ByteBuffer byteBuffer = ByteBuffer.allocate(512);                while (true) &#123; //循环读取            //这里有一个重要的操作，一定不要忘了            /*            public final Buffer clear() &#123;                position = 0;                limit = capacity;                mark = -1;                return this;            &#125;            */            byteBuffer.clear(); //清空 buffer            int read = fileChannel01.read(byteBuffer);            System.out.println(&quot;read = &quot; + read);            if (read == -1) &#123; //表示读完                break;            &#125;            //将 buffer 中的数据写入到 fileChannel02--2.txt            byteBuffer.flip();            fileChannel02.write(byteBuffer);        &#125;        //关闭相关的流        fileInputStream.close();        fileOutputStream.close();    &#125;&#125;</code></pre><p>4 . 拷贝文件transferFrom 方法</p><pre><code class="language-java">import java.io.FileInputStream;import java.io.FileOutputStream;import java.nio.channels.FileChannel;public class NIOFileChannel04 &#123;    public static void main(String[] args) throws Exception &#123;        //创建相关流        FileInputStream fileInputStream = new FileInputStream(&quot;d:\\a.jpg&quot;);        FileOutputStream fileOutputStream = new FileOutputStream(&quot;d:\\a2.jpg&quot;);                //获取各个流对应的 FileChannel        FileChannel sourceCh = fileInputStream.getChannel();        FileChannel destCh = fileOutputStream.getChannel();        //使用 transferForm 完成拷贝        destCh.transferFrom(sourceCh, 0, sourceCh.size());        //关闭相关通道和流        sourceCh.close();        destCh.close();        fileInputStream.close();        fileOutputStream.close();    &#125;&#125;</code></pre><h3 id="Buffer-和-Channel-注意事项"><a href="#Buffer-和-Channel-注意事项" class="headerlink" title="Buffer 和 Channel 注意事项"></a>Buffer 和 Channel 注意事项</h3><p><strong>1. ByteBuffer 支持类型化的 put 和 get，put 放什么，get 取出什么，不然出现 BufferUnderflowException 异常</strong></p><pre><code class="language-java">import java.nio.ByteBuffer;public class NIOByteBufferPutGet &#123;    public static void main(String[] args) &#123;                //创建一个 Buffer        ByteBuffer buffer = ByteBuffer.allocate(64);        //类型化方式放入数据        buffer.putInt(100);        buffer.putLong(9);        buffer.putChar(&#39;尚&#39;);        buffer.putShort((short) 4);        //取出        buffer.flip();                System.out.println();                System.out.println(buffer.getInt());        System.out.println(buffer.getLong());        System.out.println(buffer.getChar());        System.out.println(buffer.getShort());    &#125;&#125;</code></pre><p><strong>2. 普通 Buffer 转成只读 Buffer</strong></p><pre><code class="language-java">import java.nio.ByteBuffer;public class ReadOnlyBuffer &#123;    public static void main(String[] args) &#123;        //创建一个 buffer        ByteBuffer buffer = ByteBuffer.allocate(64);        for (int i = 0; i &lt; 64; i++) &#123;            buffer.put((byte) i);        &#125;        //读取        buffer.flip();        //得到一个只读的 Buffer        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();        System.out.println(readOnlyBuffer.getClass());        //读取        while (readOnlyBuffer.hasRemaining()) &#123;            System.out.println(readOnlyBuffer.get());        &#125;        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException    &#125;&#125;</code></pre><p><strong>3. NIO 中 MappedByteBuffer，可以让文件直接在堆外内存修改</strong></p><pre><code class="language-java">import java.io.RandomAccessFile;import java.nio.MappedByteBuffer;import java.nio.channels.FileChannel;/** * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次 */public class MappedByteBufferTest &#123;    public static void main(String[] args) throws Exception &#123;        RandomAccessFile randomAccessFile = new RandomAccessFile(&quot;1.txt&quot;, &quot;rw&quot;);        //获取对应的通道        FileChannel channel = randomAccessFile.getChannel();        /**         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式         * 参数 2：0：可以直接修改的起始位置         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存         * 可以直接修改的范围就是 0-5         * 实际类型 DirectByteBuffer         */        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);        mappedByteBuffer.put(0, (byte) &#39;H&#39;);        mappedByteBuffer.put(3, (byte) &#39;9&#39;);        mappedByteBuffer.put(5, (byte) &#39;Y&#39;);//IndexOutOfBoundsException        randomAccessFile.close();        System.out.println(&quot;修改成功~~&quot;);    &#125;&#125;</code></pre><ol start="4"><li><strong>NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering</strong></li></ol><pre><code class="language-java">import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Arrays;/** * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散] * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读 */public class ScatteringAndGatheringTest &#123;    public static void main(String[] args) throws Exception &#123;                //使用 ServerSocketChannel 和 SocketChannel 网络        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);        //绑定端口到 socket，并启动        serverSocketChannel.socket().bind(inetSocketAddress);        //创建 buffer 数组        ByteBuffer[] byteBuffers = new ByteBuffer[2];        byteBuffers[0] = ByteBuffer.allocate(5);        byteBuffers[1] = ByteBuffer.allocate(3);        //等客户端连接 (telnet)        SocketChannel socketChannel = serverSocketChannel.accept();        int messageLength = 8; //假定从客户端接收 8 个字节        //循环的读取        while (true) &#123;            int byteRead = 0;            while (byteRead &lt; messageLength) &#123;                long l = socketChannel.read(byteBuffers);                byteRead += l; //累计读取的字节数                System.out.println(&quot;byteRead = &quot; + byteRead);                //使用流打印,看看当前的这个 buffer 的 position 和 limit                Arrays.asList(byteBuffers).stream().map(buffer -&gt; &quot;position = &quot; + buffer.position() + &quot;, limit = &quot; + buffer.limit()).forEach(System.out::println);            &#125;            //将所有的 buffer 进行 flip            Arrays.asList(byteBuffers).forEach(buffer -&gt; buffer.flip());            //将数据读出显示到客户端            long byteWirte = 0;            while (byteWirte &lt; messageLength) &#123;                long l = socketChannel.write(byteBuffers);//                byteWirte += l;            &#125;                        //将所有的buffer进行clear            Arrays.asList(byteBuffers).forEach(buffer -&gt; &#123;                buffer.clear();            &#125;);                        System.out.println(&quot;byteRead = &quot; + byteRead + &quot;, byteWrite = &quot; + byteWirte + &quot;, messagelength = &quot; + messageLength);        &#125;    &#125;&#125;</code></pre><h2 id="3-Selector（选择器）"><a href="#3-Selector（选择器）" class="headerlink" title="3. Selector（选择器）"></a>3. Selector（选择器）</h2><h3 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h3><p>NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。NIO 实现了 IO 多路复用中的 Reator 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个 Channel 上的事件，从而让一个线程能够处理多个事件。</p><p>通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入到阻塞状态一直等待，而是鸡血轮询其他 Channel，找到 IO 事件已经到达的 Channel 执行。</p><p>以为创建和切换线程的开销很大，因此使用一个线程处理多个事件显然比一个线程处理一个事件具有更好的性能。</p><p> <img src="/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png" alt="[]"></p><ol><li>Java 中的 NIO 可以用一个线程，处理多个客户端连接，就会使用到 Selector（选择器）</li><li>多个 Channel 以事件的方式注册到 Selector</li><li>只有在连接通道有真正的读写事件的时候，才会进行读写，减少系统开销</li><li>避免了<code>多线程之间的上下文切换导致的开销</code></li></ol><pre><code class="language-java">//Selector 类是一个抽象类，常用方法和说明如下：public abstract class Selector implements Closeable&#123;public static Selector open();//监控所有注册的通道，当其中有IO操作可以进行时，将SelectionKey加入到内部的集合中并返回，参数用来设置超时时间public Set&lt;SelectionKey&gt; selectedKey();//从内部集合中得到所有的SelectionKey&#125;</code></pre><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ol><li><strong>创建选择器</strong></li></ol><pre><code class="language-java">Selector selector = Selector.open();</code></pre><ol start="2"><li><strong>将通道注册到选择器上</strong></li></ol><pre><code class="language-java">ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector,SelectionKey.OP_ACCEPT);</code></pre><p>将通道注册到选择器上，还需要指定要注册的具体事件，主要有以下几类：</p><p><code>SelectionKey. OP_CONNECT</code>、<code>SelectionKey. OP_ACCEPT</code>、<code>SelectionKey. OP_READ</code>、 <code>SelectionKey. OP_WRITE</code></p><p>他们在 SelectionKey 的定义如下：</p><pre><code class="language-java">public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4;</code></pre><p>可以看出每个事件都能当成一个位域，从而组成事件集整数。例如：</p><pre><code class="language-java">int intersetSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;</code></pre><ol start="3"><li><strong>监听事件</strong></li></ol><pre><code class="language-java">int num = selector.select();</code></pre><p>使用 <code>select()</code> 方法来监听到达的事件，它会一直阻塞知道有至少一件事件到达。</p><ol start="4"><li><strong>获取到达的事件</strong></li></ol><pre><code class="language-java">Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while(keyIterator.hasNext())&#123;SelectionKey keyu = keyIterator.next();if(key.isAcceptabnle())&#123;// ...&#125;else if(key.isReadable())&#123;// ...&#125;keyIterator.remove();&#125;</code></pre><ol start="5"><li><strong>时间循环</strong></li></ol><p>因为一次 select() 调动不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理时间的代码一般会放在一个死循环内。</p><pre><code class="language-java">while (true) &#123; int num = selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123;   // ... &#125; else if (key.isReadable()) &#123;  // ... &#125; keyIterator.remove(); &#125;&#125;</code></pre><h3 id="套接字-NIO-实例"><a href="#套接字-NIO-实例" class="headerlink" title="套接字 NIO 实例"></a>套接字 NIO 实例</h3><pre><code class="language-java">public class NIOServer &#123; public static void main(String[] args) throws IOException &#123;Selector selector = Selector.open();ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT);ServerSocket serverSocket = ssChannel.socket();InetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888);serverSocket.bind(address);while(true)&#123;selector.select();Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext())&#123;SelectionKey key = keyIterator.next();if (key.isAcceptable()) &#123;ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();// 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept();sChannel.configureBlocking(false);// 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ);&#125;else if (key.isReadable()) &#123;SocketChannel sChannel = (SocketChannel) key.channel();System.out.println(readDataFromSocketChannel(sChannel));sChannel.close();&#125; keyIterator.remove();&#125;&#125; &#125;private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123;ByteBuffer buffer = ByteBuffer.allocate(1024);StringBuilder data = new StringBuilder();while(true) &#123;buffer.clear();int n = sChannel.read(buffer);if (n == -1) &#123;break;&#125;buffer.flip();int limit = buffer.limit();char[] dst = new char[limit];for (int i = 0;i &lt; limit;i++) &#123;dst[i] = (char) buffer.get(i);&#125;data.append(dst);buffer.clear(); &#125; return data.toString(); &#125; &#125;</code></pre><pre><code class="language-java">public class NIOClient &#123;public static void main(String[] args) throws IOException&#123;Socket socket = new Socket(&quot;127.0.0.1&quot;，8888);OutputStream out = socket.getOutputStream();String s = &quot;hello world&quot;;out.write(s.getBytes());out.close();&#125;&#125;</code></pre><h2 id="典型的多路复用-IO-实现"><a href="#典型的多路复用-IO-实现" class="headerlink" title="典型的多路复用 IO 实现"></a>典型的多路复用 IO 实现</h2><p>目前流程的多路复用 IO 实现主要宝库了四种：select、poll、epoll、kqueue。以下是其特性及区别：</p><table><thead><tr><th align="center">IO 模型</th><th align="center">相对性能</th><th align="center">关键思路</th><th align="center">操作系统</th><th align="center">Java 支持情况</th></tr></thead><tbody><tr><td align="center">select</td><td align="center">较高</td><td align="center">Reactor</td><td align="center">Win&#x2F;Linux</td><td align="center">支持，Reactor 模式（反应器设计模式）。Linux kernels 2.4 内核版本之前，默认用的是 select ；目前 windows 下对吧同步 IO 的支持，都是 select 模型</td></tr><tr><td align="center">poll</td><td align="center">较高</td><td align="center">Reactor</td><td align="center">Linux</td><td align="center">Linux 下的 Java 的 NIO 框架，Linux kernels 2.6 内核版本之前使用 poll 进行支持。也是使用的 Reactor 模式</td></tr><tr><td align="center">epoll</td><td align="center">高</td><td align="center">Reactor&#x2F;Proactor</td><td align="center">Linux</td><td align="center">Linux kernels 2.6 内核版本之后使用 epoll 进行支持</td></tr><tr><td align="center">kqueue</td><td align="center">高</td><td align="center">Proactor</td><td align="center">Linux</td><td align="center">目前 Java 版本不支持</td></tr></tbody></table><h3 id="1-Reactor事件驱动模型"><a href="#1-Reactor事件驱动模型" class="headerlink" title="1. Reactor事件驱动模型"></a>1. Reactor事件驱动模型</h3><p> <img src="/img/10d0080498aba2649f1c04067965b579_MD5.png" alt="[]"></p><p>从图上可知：一个完整的 Reactor 事件驱动模型是有四个部分组成：客户端 Client，Reactor，Acceptor 和时间处理 Handler。其中 Acceptor 会不间断的接收客户端的连接请求，然后通过 Reactor 分发到不同 Handler 进行处理。改进后的 Reactor 有如下优点：</p><ul><li>虽然同是由一个线程接收连接请求进行网络读写，但是 Reactor 将客户端连接，网络读写，业务处理三大部分拆分，从而极大提高工作效率。</li><li>Reactor 是以事件驱动的，相比传统 IO 阻塞式的，不必等待，大大提升了效率。</li></ul><h3 id="2-Reactor-模型——业务处理和-IO-分离"><a href="#2-Reactor-模型——业务处理和-IO-分离" class="headerlink" title="2. Reactor 模型——业务处理和 IO 分离"></a>2. Reactor 模型——业务处理和 IO 分离</h3><p>在上面的处理模型中，由于网络读写是在同一个线程里面。在高并发情况下，会出现两个瓶颈：</p><ul><li>高频率的读写事件处理</li><li>大量的业务处理</li></ul><p>基于上述瓶颈，可以将业务处理和 IO 读写分离出来：</p><p> <img src="/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png" alt="[]"></p><p>如图可以看出，相对基础 Reactor 模型，该模型有如下特点：</p><ul><li>使用一个线程进行客户端连接和网络读写</li><li>客户端连接之后，将该连接交给线程池进行加解码以及业务处理</li></ul><p>这种模型在接收请求进行网络读写的同时，也在进行业务处理，大大提高了系统的吞吐量。但是也有不足的地方：</p><ul><li>网络读写是一个比较消耗 CPU 的操作，在高并发的情况下，将有大量的客户端需要网络读写，此时一个线程处理不了这么多的请求。</li></ul><h3 id="3-Reactor——并发读写"><a href="#3-Reactor——并发读写" class="headerlink" title="3. Reactor——并发读写"></a>3. Reactor——并发读写</h3><p>由于高并发的网络读写是系统一个瓶颈，所以针对这种情况，改进了模型，如图所示：</p><p> <img src="/img/870a39b7312d1d18324d3aefa613ab37_MD5.png" alt="[]"><br>由图可以看出，在原有 Reactor 模型上，同时将 Reactor 拆分成 mainReactor 和 subReactor 。其中 mainReactor 主要负责客户端的请求连接，subReactor 通过一个线程池进行支撑，主要负责网络读写，因为线程池的原因，可以进行多线程并发读写，大大提升了网络读写的效率。业务处理也是通过线程池进行。通过这种方式，可以进行百万级别的连接。</p><h3 id="4-Reactor-模型示例"><a href="#4-Reactor-模型示例" class="headerlink" title="4. Reactor 模型示例"></a>4. Reactor 模型示例</h3><p>对于上述的 Reactor 模型，主要有三个核心需要实现：Acceptor，Reactor 和 Handler。具体实现代码如下：</p><pre><code class="language-java">public class Reactor implements Runnable&#123;private final Selector selector;private final ServerSocketChannel serverSocket;public Reactor(int port) throws IOException&#123;serverSocket = ServerSocketChannel.open();//创建服务端的ServerSocketChannelserverSocket.configureBlocking(false);//设置为非阻塞模式selector = Selector.open();//创建一个selector选择器SelectionKey key = serverSocket.register(selector,SelectionKey.OP_ACCEPT);serverSocket.bind(new InetSocketAddress(port));//绑定服务端端口key.attach(new Acceptor(serverSocket));//为服务端Channel绑定一个Acceptor&#125;@Overridepublic void run()&#123;try&#123;while(！Thread.interrupted())&#123;selector.select();//服务端使用一个线程不停接收连接请求Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; itetrator = keys.iterator();while(iterator.hasNext())&#123;dispatch(iterator.next());iterator.remove();&#125;selector.selectNow();&#125;&#125;catch(IOException e)&#123;e.printStackTrace();&#125;&#125;private void dispatch(SelectionKey key) throws IOException&#123;//这里的attachment也即前面的为服务端Channel绑定的Acceptor，调用其run()方法进行分发Runnable attachment = (Runable)key.attachment();attachment.run();&#125;&#125;</code></pre><p>这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码：</p><pre><code class="language-java">public class Acceptor implements Runnable&#123;private final ExecuteorService executor = Exxcutors.newFixedThreadPool(20);private final ServerSocketChannel serverSocket;public Acceptor(ServerSocketChannel serverSocket)&#123;this.serverSocket = serverSocket;&#125;@Overridepublic void run()&#123;try&#123;SocketChannel channel = serverSocket.accept();if(null != channel)&#123;executor.execute(new Handler(channel));&#125;&#125;catch(IOException e)&#123;e.printStackTrace();&#125;&#125;&#125;</code></pre><p>这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑：</p><pre><code class="language-java">public class Handler implements Runnable&#123;private volatile static Selector selector;private final SocketChannel channel;private SelectionKey key;private volatile ByteBuffer input = ByteBuffer.allocate(1024);private volatile ByteBuffer output = ByteBuffer.allocate(1024);public Handle(SocketChannel channel) throws IOException&#123;this.channel = channel;channel.configureBlocking(false);//设置客户端连接为非阻塞模式selector = Selector.open();//为客户端创建一个选择器key = channel.register(selector,SelectionKey.OP_READ);//注册客户端Channel的读事件&#125;@Overridepublic void run()&#123;try&#123;while(selector.isOpen() &amp;&amp; channel.isOpen())&#123; Set&lt;SelectionKey&gt; keys = select();//等待客户端事件发生 Iterator&lt;SelectionKey&gt; iterator = keys.iterator();while(iterator.hasNext())&#123;SelectionKey key = iterator.next();iterator.remove();//如果当前是读事件，则读取数据if(key.isReadable())&#123;read(key);&#125;else if(key.isWritable())&#123;write(key)&#125;&#125;&#125;&#125;catch(IOException e)&#123;e.printStackTrace();&#125;&#125;//读取客户端发送的数据private void read(SelectionKey key) throws IOException&#123;channel.read(input);if(input.position() == 0)&#123;return ;&#125;input.flip();process();//对读数据进行业务处理input.clear();key.interstOps(SelectionKey.OP_WRITE);//读取完成后监听写入事件&#125;private void write(SelectionKey key) throws IOException&#123;output.flip();if(channel.isOpen())&#123;channel.write(output);//当有写入事件时，将业务处理的结果写入到客户端Channel中key.channel();channel.close();output.clear();&#125;&#125;//进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈，则将处理过程放入到线程池里面即可，并且使用一个Future获取处理结果，最后写入到客户端Channel中private void process()&#123;byte[] bytes = new byte[input.remaining()];input.get(bytes);String message = new String(bytes,CharsetUtil.UTF_8);System.out.println(&quot;receive message from client: \n&quot; +message);output.put(&quot;hello client&quot;.getBytes());&#125;&#125;</code></pre><p>在 Handler 中，主要进行的就是每个客户端 Channel 创建一个 Selector，并且监听该 Channel 的网络读写事件。当有事件到达时，进行数据的读写，而业务操作交友具体的业务线程池处理。</p><h1 id="三、AIO（-Asynchronous-I-O）"><a href="#三、AIO（-Asynchronous-I-O）" class="headerlink" title="三、AIO（ Asynchronous I&#x2F;O）"></a>三、AIO（ Asynchronous I&#x2F;O）</h1><ol><li>JDK7 引入了 Asynchronous I&#x2F;O，即 AIO。在进行 I&#x2F;O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理</li><li>AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用</li></ol><h3 id="异步-IO"><a href="#异步-IO" class="headerlink" title="异步 IO"></a>异步 IO</h3><p>之前主要介绍了阻塞式同步 IO，非阻塞式同步 IO，多路复用 IO 这三种 IO 模型。而异步 IO 是采用“订阅-通知”模式，即应用程序向操作系统注册 IO 监听，然后继续做自己的事情。当操作系统发生 IO 事件，并且准备好数据后，主动通知应用程序，触发相应的函数：</p><p> <img src="/img/3a01157436842562f7f21f8b4c4549d4_MD5.png" alt="[]"></p><p>和同步 IO 一样，异步 IO 也是由操作系统进行支持的。Windows 系统提供了一种异步 IO 技术：IOCP（I&#x2F;O Completion Port，I&#x2F;O 完成端口）；<br>Linux 下由于没有这种异步 IO 技术，所以使用的是 epoll（上文介绍过的一种多路复用 IO 技术的实现）对异步 IO 进行模拟。</p><h3 id="Java-AIO-框架解析"><a href="#Java-AIO-框架解析" class="headerlink" title="Java AIO 框架解析"></a>Java AIO 框架解析</h3><p> <img src="/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png" alt="[]"></p><p>以上结构主要是说明 JAVA AIO 中类设计和操作系统的相关性。</p><blockquote><p>上述所有代码仓库地址：<a href="https://github.com/z1gui/netty_io">https://github.com/z1gui/netty_io</a></p></blockquote><p>参考资料：</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/520809188?utm_id=0">BIO、NIO、AIO区别详解</a></p><p><a href="https://pdai.tech/md/java/io/java-io-overview.html">♥Java IO知识体系详解♥</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;BIO&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;NIO&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;AIO&lt;/th&gt;
&lt;/tr&gt;
&lt;/th</summary>
      
    
    
    
    <category term="后端" scheme="https://www.lazydaily.cn/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="java" scheme="https://www.lazydaily.cn/tags/java/"/>
    
    <category term="IO" scheme="https://www.lazydaily.cn/tags/IO/"/>
    
    <category term="NIO" scheme="https://www.lazydaily.cn/tags/NIO/"/>
    
    <category term="BIO" scheme="https://www.lazydaily.cn/tags/BIO/"/>
    
  </entry>
  
  <entry>
    <title>类加载器以及双亲委派模型</title>
    <link href="https://www.lazydaily.cn/761386768996885/"/>
    <id>https://www.lazydaily.cn/761386768996885/</id>
    <published>2024-08-31T16:00:00.000Z</published>
    <updated>2025-05-20T07:21:30.943Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一个类的生命周期（7个阶段）"><a href="#一个类的生命周期（7个阶段）" class="headerlink" title="一个类的生命周期（7个阶段）"></a>一个类的生命周期（7个阶段）</h3><p><strong>加载-验证-准备-解析-初始化-使用-卸载</strong></p><p><img src="/img/20200901134621820.png" alt="一个类的生命周期"><br>其中，类的加载过程是十分重要的过程。在这一过程，是由JVM提供的类加载器来完成。</p><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a><strong>类加载器</strong></h3><p>JVM提供三层类加载器</p><p><strong>启动类加载器</strong>：Bootstrap Class Loader ，是C++写的，返回为NULL（比如String类），lib&#x2F;下的jar包，比如rt.jar,jce.jar等</p><p><strong>拓展类加载器</strong>：Extension Class Loader，jre&#x2F;lib&#x2F;ext下的jar或者是指定的jar</p><p><strong>应用程序类加载器</strong>：Application  Class Loader，加载calsspath指定内容</p><p>当然自己也可以定义加载器，不算入JVM中的，<strong>自定义加载器</strong>：Custom ClassLoader，自定义加载器，支持一些个性化的扩展功能</p><pre><code class="language-text">Xbootclasspath设置启动类加载器的路径</code></pre><h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a><strong>双亲委派模型</strong></h3><p><img src="/img/20200901135402519.png" alt="双亲委派模型"><br>每一层的类加载器都有上层的加载器，称为父类加载器，Bootstrap加载器最上层的类加载器，主要加载一些重要的类，如Object类，String类等。当类需要加载的时候子类加载器会依次向上委托父类加载器进行加载，并向上询问是否已经被加载，如果父类没有被加载，则向下尝试子类加载器是否可加载，直到该类被加载，过程结束。这就是双亲委派模型机制。</p><p>总结：<strong>向上委托并询问，向下尝试加载</strong></p><p>优势：<strong>稳定</strong>，当自己重写了个基础类（Object类，String类等）进行加载的时候，子类加载器依次向上委托基础类给父类加载器，到了Bootstrap类加载器发现rt.jar中有，然后就直接加载，返回加载成功。这样保证了JVM运行的安全稳定。</p><p><strong>对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。</strong></p><h4 id="打破双亲委派模型的示例"><a href="#打破双亲委派模型的示例" class="headerlink" title="打破双亲委派模型的示例"></a><strong>打破双亲委派模型的示例</strong></h4><p>虽然双亲委派模型能够保证JVM稳定运行，但有些时候根据场景，我们需要打破这种机制。</p><h5 id="1-Tomca类加载机制"><a href="#1-Tomca类加载机制" class="headerlink" title="1.Tomca类加载机制"></a>1.Tomca类加载机制</h5><p><img src="/img/20200901160002516.png" alt="Tomcat加载机制"></p><p>Tomcat中自定义的Common加载器：Catalina类+Shared类加载器</p><p>tomcat通过war包进行的应用发布，其实时违反了双亲委派机制原则。因为不同的项目可能用到不同版本的第三方，即需要不同webApp类加载器加载不同版本的第三方，需要隔离，所以要破坏双亲委派模型。</p><p><strong>tomcat的设计如何破坏了双亲委派机制？</strong></p><p>tomcat中存在三种类加载器，Common加载器：Catalina类+Shared类加载器，在进行类加载的时候是这样处理的：</p><p>1.首先判断这个类是否已经被加载了，如果被加载了就返回，否则下一步；</p><p>2.尝试通过Appcalition ClassLoader进行加载，主要是避免一些基础类（Object，String类）被web中的类覆盖，导致不安全，如果加载了就返回，否则下一步；</p><p>3.如果前两步都没有加载到类，就启用webApp类加载器进行加载，如果被加载了就返回，否则下一步；</p><p>4.最后还没有加载的话，就委托父类加载器Common ClassLoader进行加载。</p><p><strong>但是你自己写一个 ArrayList或者HashMap时候，放在应用目录里，tomcat 依然不会加载（会在第二步时通过Application类加载器进行加载）。Tomca类加载机制只是自定义的加载器顺序不同，但对于顶层来说，还是一样的。</strong></p><h5 id="2-SPI（Service-Provider-Infreface）"><a href="#2-SPI（Service-Provider-Infreface）" class="headerlink" title="2.SPI（Service Provider Infreface）"></a>2.<strong>SPI</strong>（Service Provider Infreface）</h5><p>Java 中有一个 SPI 机制，全称是 Service Provider Interface，是 Java 提供的一套用来被第三方实现或者扩展的服务提供接口，设计模式：基于接口的编程，是接口+实现类+配置文件</p><p>其中最有代表性的，<strong>JDBC，数据库连接</strong></p><p><strong>如何破环双亲委派？</strong></p><p>原本应该是通过BootStrap ClassLoader进行加载，没有代码进行实现加载，只能获取当前线程上下文加载器，即整个web的Application ClassLoder，所以最后其实在使用的Application类加载器加载</p><p><img src="/img/20200901160256824.png" alt="SPI"><br>源码分析</p><pre><code class="language-java">public class Test&#123;//我们在JDBC连接数据库的时候往往通过一行代码就能实现//Class.forName(&quot;xx&quot;);可以不用写    Connection conn= DriverManager.getConnection(url, user, password);//当getConnection被调用的时候，DriverManager中有个static静态代码块进行执行    /**     * Load the initial JDBC drivers by checking the System property     * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism     */    static &#123;        loadInitialDrivers();        println(&quot;JDBC DriverManager initialized&quot;);    &#125;    //静态代码块执行的方法loadInitialDrivers()    private static void loadInitialDrivers() &#123;        String drivers;        try &#123;            drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123;                public String run() &#123;                    return System.getProperty(&quot;jdbc.drivers&quot;);                &#125;            &#125;);        &#125; catch (Exception ex) &#123;            drivers = null;        &#125;        // If the driver is packaged as a Service Provider, load it.        // Get all the drivers through the classloader        // exposed as a java.sql.Driver.class service.        // ServiceLoader.load() replaces the sun.misc.Providers()        AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;            public Void run() &#123;                //注意这里！！！加载Driver.class代码                ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);                Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();                /* Load these drivers, so that they can be instantiated.                 * It may be the case that the driver class may not be there                 * i.e. there may be a packaged driver with the service class                 * as implementation of java.sql.Driver but the actual class                 * may be missing. In that case a java.util.ServiceConfigurationError                 * will be thrown at runtime by the VM trying to locate                 * and load the service.                 *                 * Adding a try catch block to catch those runtime errors                 * if driver not available in classpath but it&#39;s                 * packaged as service and that service is there in classpath.                 */                try&#123;                    while(driversIterator.hasNext()) &#123;                        driversIterator.next();                    &#125;                &#125; catch(Throwable t) &#123;                    // Do nothing                &#125;                return null;            &#125;        &#125;);        println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers);        if (drivers == null || drivers.equals(&quot;&quot;)) &#123;            return;        &#125;        String[] driversList = drivers.split(&quot;:&quot;);        println(&quot;number of Drivers:&quot; + driversList.length);        for (String aDriver : driversList) &#123;            try &#123;                println(&quot;DriverManager.Initialize: loading &quot; + aDriver);                Class.forName(aDriver, true,                        ClassLoader.getSystemClassLoader());            &#125; catch (Exception ex) &#123;                println(&quot;DriverManager.Initialize: load failed: &quot; + ex);            &#125;        &#125;    &#125;    //进入到ServiceLoader之后的代码//能发现，这个加载时是获取当前线程的上下文类加载器进行加载，而这个加载器不是JVM中BootStrap类加载器，而是厂商提供的，所以加载的时候不是在BootStrap类加载器加载，在打破了双亲委派模型~    public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123;        ClassLoader cl = Thread.currentThread().getContextClassLoader();        return ServiceLoader.load(service, cl);    &#125;&#125;</code></pre><p>总结：通过源码不难看出，Class.forName(“xx”);能写且不报错，说明在JVM里面有这个Drive类的加载代码，但是只有接口，没有实现，具体实现是厂商提供的，而这个过程不遵循双亲委派机制。</p><blockquote><p>对SPI想多点了解，可参考：<br><a href="https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&mid=2247483935&idx=1&sn=e6da46cfe2df2812fd2b9e24253ec246&chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&amp;mid=2247483935&amp;idx=1&amp;sn=e6da46cfe2df2812fd2b9e24253ec246&amp;chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&amp;scene=21#wechat_redirect</a></p></blockquote><h5 id="3-OSGi——模块化（微服务）-安装、启动、停止、卸载。"><a href="#3-OSGi——模块化（微服务）-安装、启动、停止、卸载。" class="headerlink" title="3.OSGi——模块化（微服务）  安装、启动、停止、卸载。"></a>3.<strong>OSGi</strong>——模块化（微服务）  安装、启动、停止、卸载。</h5><p>原理：使类相互之间不可见，相当霸道！（后续补充）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一个类的生命周期（7个阶段）&quot;&gt;&lt;a href=&quot;#一个类的生命周期（7个阶段）&quot; class=&quot;headerlink&quot; title=&quot;一个类的生命周期（7个阶段）&quot;&gt;&lt;/a&gt;一个类的生命周期（7个阶段）&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;加载-验证-准备-解析-初始</summary>
      
    
    
    
    <category term="后端" scheme="https://www.lazydaily.cn/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="java" scheme="https://www.lazydaily.cn/tags/java/"/>
    
    <category term="类加载器" scheme="https://www.lazydaily.cn/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"/>
    
    <category term="双亲委派模型" scheme="https://www.lazydaily.cn/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>javascript中 const，var，let的区别</title>
    <link href="https://www.lazydaily.cn/761386768996512/"/>
    <id>https://www.lazydaily.cn/761386768996512/</id>
    <published>2024-07-22T16:00:00.000Z</published>
    <updated>2025-05-20T07:22:19.700Z</updated>
    
    <content type="html"><![CDATA[<p>var、const、let 同样都是声明变量的关键词。</p><h2 id="一、var-和-let-区别"><a href="#一、var-和-let-区别" class="headerlink" title="一、var 和 let 区别"></a>一、var 和 let 区别</h2><h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><p>var 的作用域只能是全局或者是整个函数块，而 let 的作用域既可以是全局变量或者是整个函数，还可以是 if, while, switch 限定的代码块。</p><pre><code class="language-javascript">function varTest() &#123;var a = 1;  &#123;    var a = 2; // 函数块中，同一个变量 console.log(a); // 2  &#125;   console.log(a); // 2&#125; function letTest() &#123;   let a = 1;   &#123;     let a = 2; // 代码块中，新的变量     console.log(a); // 2   &#125;   console.log(a); // 1 &#125; varTest(); letTest();</code></pre><p>let 声明的变量，可以比 var 声明的变量的作用有更小的限定范围，更加灵活。</p><h3 id="重复声明"><a href="#重复声明" class="headerlink" title="重复声明"></a>重复声明</h3><p>在同一个作用域中，var 允许重复声明，但是 let 不允许重复声明。</p><pre><code class="language-javascript">var a = 1;var a = 2;console.log(a) // 2function test() &#123;  var a = 3;   var a = 4;   console.log(a) // 4 &#125; test()if(false) &#123;  let a = 1;  let a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared&#125;&#125;switch(index) &#123;  case 0:    let a = 1;  break;  default:    let a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared    break;&#125;</code></pre><h3 id="绑定全局变量"><a href="#绑定全局变量" class="headerlink" title="绑定全局变量"></a>绑定全局变量</h3><p>var 在全局环境声明变量，会在全局对象里新建一个属性，而 let 在全局环境声明变量，则不会在全局对象里新建一个属性。</p><pre><code class="language-javascript">var foo = &#39;global&#39;let bar = &#39;global&#39;console.log(this.foo) // globalconsole.log(this.bar) // undefined</code></pre><p><img src="/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg" alt="[d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg]"></p><p>由上图可知，let 在全局环境声明变量 bar 保存在[[Scopes]][0]: Script 这个变量对象的属性中，而 [[Scopes]][1]: Global 就是我们常说的全局对象。</p><h3 id="变量提升和暂存死区"><a href="#变量提升和暂存死区" class="headerlink" title="变量提升和暂存死区"></a>变量提升和暂存死区</h3><p>了解变量提升，就需要了解到上线文和变量对象。详见<a href="/md/js/%E8%AF%A6%E8%A7%A3%EF%BC%9AJavaScript%E5%88%9B%E5%BB%BA%E6%89%A7%E8%A1%8C%E9%87%8A%E6%94%BE%E8%BF%87%E7%A8%8B.md">详解：javascript 创建执行释放过程</a></p><h4 id="变量提升"><a href="#变量提升" class="headerlink" title="变量提升"></a>变量提升</h4><p>所有使用 var 声明的变量都会在执行上下文的创建阶段时作为变量对象的属性被创建并初始化，这样才能保证在执行阶段能通过标识符在变量对象里找到对应变量进行赋值操作等。即 var 在声明变量构建变量的时：</p><ol><li>由名称和 undefined（形参）组成一个变量对象的属性创建（创建并初始化）</li><li>如果变量名称和之前的形参或者函数相同，则变量声明不会干扰已经存在的这类属性。</li></ol><pre><code class="language-javascript">console.log(a) // undefinedvar a = 1;console.log(a) // 1</code></pre><p>为什么 var 变量可以在声明之前使用，因为使用是在执行阶段，而在此之前的创建阶段就已经将声明的变量添加到了变量对象中，所以执行阶段通过标识符可以在变量对象中查找到，也就不会报错。</p><h4 id="暂存死区"><a href="#暂存死区" class="headerlink" title="暂存死区"></a>暂存死区</h4><p>其实 let 也存在与 var 类似的“变量提升”过程，但与 var 不同的是其在执行上下文的创建阶段，只会创建变量而不会被初始化（undefined），并且 ES6 规定了其初始化过程是在执行上下文的执行阶段（即直到它们的定义被执行时才初始化），使用未被初始化的变量将会报错。</p><blockquote><p>let and const declarations define variables that are scoped to the running execution context’s LexicalEnvironment. The variables are created when their containing Lexical Environment is instantiated but may not be accessed in any way until the variable’s LexicalBinding is evaluated. A variable defined by a LexicalBinding with an Initializer is assigned the value of its Initializer’s AssignmentExpression when the LexicalBinding is evaluated, not when the variable is created. If a LexicalBinding in a let declaration does not have an Initializer the variable is assigned the value <strong>undefined</strong> when the LexicalBinding is evaluated.</p></blockquote><p>在变量初始化前访问该变量会导致 ReferenceError，因此从进入作用域创建变量，到变量开始可被访问的一段时间（过程），就称为暂存死区(Temporal Dead Zone)。</p><pre><code class="language-javascript">console.log(bar); // undefinedconsole.log(foo); // ReferenceError: foo is not definedvar bar = 1;let foo = 2;var foo = 33;&#123;  let foo = (foo + 55); // ReferenceError: foo is not defined&#125;</code></pre><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol><li>var 声明的变量在执行上下文创建阶段就会被「创建」和「初始化」，因此对于执行阶段来说，可以在声明之前使用。</li><li>let 声明的变量在执行上下文创建阶段只会被「创建」而不会被「初始化」，因此对于执行阶段来说，如果在其定义执行前使用，相当于使用了未被初始化的变量，会报错。</li></ol><h2 id="二、let-和-const-区别"><a href="#二、let-和-const-区别" class="headerlink" title="二、let 和 const 区别"></a>二、let 和 const 区别</h2><p>const 与 let 很类似，都具有上面提到的 let 的特性，唯一区别就在于 const 声明的是一个只读变量，声明之后不允许改变其值。因此，const 一旦声明必须初始化，否则会报错。</p><p>示例代码：</p><pre><code class="language-javascript">let a;const b = &quot;constant&quot;a = &quot;variable&quot;b = &#39;change&#39; // TypeError: Assignment to constant variable</code></pre><p><strong>如何理解声明之后不允许改变其值？</strong></p><p>其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动（即栈内存在的值和地址）。</p><p>javascript 的数据类型分为两类：原始值类型和对象（Object类型）。</p><p>对于原始值类型（undefined、null、true&#x2F;false、number、string），值就保存在变量指向的那个内存地址（在栈中），因此 const 声明的原始值类型变量等同于常量。</p><p>对于对象类型（object，array，function等），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是不可修改的，至于指针指向的数据结构是无法保证其不能被修改的（在堆中）。</p><p>示例代码：</p><pre><code class="language-javascript">const obj = &#123;  value: 1&#125;obj.value = 2;console.log(obj) // &#123; value: 2 &#125;obj = &#123;&#125;</code></pre><p>参考资料：</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/556482226?utm_id=0">深入理解 JS：var、let、const 的异同</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;var、const、let 同样都是声明变量的关键词。&lt;/p&gt;
&lt;h2 id=&quot;一、var-和-let-区别&quot;&gt;&lt;a href=&quot;#一、var-和-let-区别&quot; class=&quot;headerlink&quot; title=&quot;一、var 和 let 区别&quot;&gt;&lt;/a&gt;一、var 和 l</summary>
      
    
    
    
    <category term="前端" scheme="https://www.lazydaily.cn/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="javascript" scheme="https://www.lazydaily.cn/tags/javascript/"/>
    
  </entry>
  
  <entry>
    <title>为什么总是乱码？来看看编码格式吧</title>
    <link href="https://www.lazydaily.cn/7613867548996883/"/>
    <id>https://www.lazydaily.cn/7613867548996883/</id>
    <published>2024-03-20T16:00:00.000Z</published>
    <updated>2025-05-20T07:22:00.347Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、-ASCII-码"><a href="#一、-ASCII-码" class="headerlink" title="一、 #ASCII 码"></a>一、 #ASCII 码</h2><p>计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 256 个状态，每个状态表示一个符号。</p><p>ASCII 码一共规定了128个字符的编码，比如空格 SPACE 是32（二进制00100000），大写的字母 A 是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号）。ASCII 码只占用了一个字节的后面7位，最前面的一位统一规定为0。</p><p><img src="/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg" alt="ASCII码"></p><h2 id="二、非-ASCII-编码"><a href="#二、非-ASCII-编码" class="headerlink" title="二、非 ASCII 编码"></a>二、非 ASCII 编码</h2><p>英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。</p><p>所有这些编码方式中，0-127表示的符号是一样的，不一样的只是128-255的这一段，不同的国家相同的 ASCII 码表示的可能是不同的符号。</p><p>至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312 ，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 &#x3D; 65536 个符号。</p><h2 id="三、-Unicode-字符集"><a href="#三、-Unicode-字符集" class="headerlink" title="三、 #Unicode 字符集"></a>三、 #Unicode 字符集</h2><p>将世界上多有文字都进行编码，就形成了 Unicode。Unicode 的规模可以容纳100多万个符号，每个符号的编码都不一样。比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母 A，U+4E25表示汉字严。</p><p>但是，Unicode 只是字符集，它之规定了符号的二进制代码，却不规定编码方式。比如：汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节（16 位二进制数）。如果将 0 补全之后存储，计算机读取的时候，他不清楚到底是（01001110）+（00100101）两个 ASCII 码，还是 （100111000100101）单个 Unicode 值。那么就出现了其他的编码方式。</p><h2 id="四、-UTF-8-编码方式"><a href="#四、-UTF-8-编码方式" class="headerlink" title="四、 #UTF-8 编码方式"></a>四、 #UTF-8 编码方式</h2><p>UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。</p><p>UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。</p><p><strong>UTF-8 的编码规则很简单，只有二条：</strong></p><ul><li><p>1）对于单字节的符号：字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的；</p></li><li><p>2）对于 n 字节的符号（n &gt; 1）：第一个字节的前 n 位都设为 1，第 n + 1 位设为 0，后面字节的前两位一律设为 10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。</p></li></ul><p><img src="/img/c17560b740940d095c678b2769092f11_MD5.jpeg" alt="Unicode编码和UTF-8编码方式"></p><p><strong>如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。</strong></p><p>下面，还是以汉字严为例，演示如何实现 UTF-8 编码。</p><p>严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的 x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是 E4B8A5。</p><p>如果保存的编码模式不同，”严”对应的值不同：</p><ul><li><p>1）ANSII：文件的编码就是两个字节 D1 CF，这正是严的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。</p></li><li><p>2）Unicode：编码是四个字节 FF FE 25 4E，其中 FF FE 表明是小头方式存储，真正的编码是4E25。</p></li><li><p>3）Unicode big endian：编码是四个字节 FE FF 4E 25，其中 FE FF 表明是 大头方式 存储。</p></li><li><p>4）UTF-8：编码是六个字节 EF BB BF E4 B8 A5，前三个字节 EF BB BF 表示这是 UTF-8 编码，后三个 E4B8A5 就是严的具体编码，它的存储顺序与编码顺序是一致的。</p></li></ul><h2 id="五、GB-系列"><a href="#五、GB-系列" class="headerlink" title="五、GB 系列"></a>五、GB 系列</h2><h4 id="GB2312-字符集"><a href="#GB2312-字符集" class="headerlink" title="#GB2312 字符集"></a>#GB2312 字符集</h4><p>天朝专家把那些127号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。这就是 GB2312， #GBK （即 CP936 字符集）和 #GB18030 是对 GB2312 的拓展。</p><h4 id="GBK-编码方式"><a href="#GBK-编码方式" class="headerlink" title="#GBK 编码方式"></a>#GBK 编码方式</h4><p>由于 GB 2312-80只收录6763个汉字，有不少汉字，如部分在 GB 2312-80推出以后才简化的汉字（如”啰”），部分人名用字（如中国前总理***的”*“字），台湾及香港使用的繁体字，日语及朝鲜语汉字等，并未有收录在内。于是厂商微软利用 GB 2312-80未使用的编码空间，收录 GB 13000.1-93全部字符制定了 GBK 编码。根据微软资料，GBK 是对 GB2312-80的扩展，也就是 CP936字符集 (Code Page 936)的扩展（之前 CP936和 GB 2312-80一模一样），最早实现于 Windows 95简体中文版。虽然 GBK 收录 GB 13000.1-93的全部字符，但编码方式并不相同。GBK 自身并非国家标准，只是曾由国家技术监督局标准化司、电子工业部科技与质量监督司公布为”技术规范指导性文件”。原始 GB13000一直未被业界采用，后续国家标准 #GB18030 技术上兼容 GBK 而非 GB13000。</p><h4 id="GB18030-字符集"><a href="#GB18030-字符集" class="headerlink" title="#GB18030 字符集"></a>#GB18030 字符集</h4><p>全称：国家标准 GB 18030-2005《信息技术中文编码字符集》，是中华人民共和国现时最新的内码字集，是 GB 18030-2000《信息技术信息交换用汉字编码字符集的扩充》的修订版。与 GB 2312-1980完全兼容，与 GBK 本兼容，支持 GB 13000及 Unicode 的全部统一汉字，共收录汉字70244个。</p><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><h4 id="字符集-："><a href="#字符集-：" class="headerlink" title="字符集 ："></a>字符集 ：</h4><p>ASCII 字符集：常规的字符集，表示英文以及部分符号。</p><p>Unicode 字符集：表示世界上所有字符，统一的字符集。</p><p>GB2312 字符集：适配汉字，ASCII 字符集的中文拓展字符集。</p><p>CP936 字符集：GBK 编码方式使用的字符集，GB2312 的拓展表。</p><p>GB18030 字符集：GB2312 的拓展表，包含全部汉字。</p><p>#编码方式 ：</p><p>UTF-8 编码方式：是一种对 Unicode 字符集的编码方式，字符由不定字节长度表示。</p><p>UTF-16 编码方式：是一种对 Unicode 字符集的编码方式，字符用两个字节或四个字节表示。</p><p>UTF-32 编码方式：是一种对 Unicode 字符集的编码方式，字符用四个字节表示。</p><p>GBK 编码方式：使用CP936 编码表，是对 ASCII 表的中文适配。</p><p><strong>简单来说：Unicode、GBK 和 Big5码等就是编码的值（也就是术语“字符集”），而 UTF-8、UTF-16、UTF32之类就是这个值的表现形式（即术语“编码格式”）。</strong></p><p>另外：</p><p><strong>Unicode、GBK和Big5码等字符集是不兼容的，同一个汉字在这三个字符集里的码值是完全不一样的。如＂汉＂的Unicode值与gbk就是不一样的，假设Unicode为a040，GBK为b030。以UTF-8为例，UTF-8码完全只针对Unicode来组织的，如果GBK要转UTF-8必须先转Unicode码，再转UTF-8就OK了。</strong></p><p>即GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换：</p><blockquote><p>1）GBK、GB2312 –先转–&gt; Unicode –再转–&gt; UTF8  </p></blockquote><blockquote><p>2）UTF8 –先转–&gt; Unicode –再转–&gt; GBK、GB2312</p></blockquote><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h4 id="BIG5字符集-编码"><a href="#BIG5字符集-编码" class="headerlink" title="BIG5字符集&amp;编码"></a>BIG5字符集&amp;编码</h4><p>Big5，又称为大五码或五大码，是使用繁体中文（正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。中文码分为内码及交换码两类，Big5属中文内码，知名的中文交换码有 CCCII、CNS11643。Big5虽普及于台湾、香港与澳门等繁体中文通行区，但长期以来并非当地的国家标准，而只是业界标准。倚天中文系统、Windows 等主要系统的字符集都是以 Big5准，但厂商又各自增加不同的造字与造字区，派生成多种不同版本。2003年，Big5被收录到 CNS11643中文标准交换码的附录当中，取得了较正式的地位。这个最新版本被称为 Big5-2003。</p><p>Big5码是一套双字节字符集，使用了双八码存储方法，以两个字节来安放一个字。第一个字节称为”高位字节”，第二个字节称为”低位字节”。”高位字节”使用了0x81-0xFE，”低位字节”使用了0x40-0x7E，及0xA1-0xFE。</p><h4 id="大头方式、小头方式"><a href="#大头方式、小头方式" class="headerlink" title="大头方式、小头方式"></a>大头方式、小头方式</h4><p>上一节已经提到，UCS-2 格式可以存储 Unicode 码（码点不超过0xFFFF）。以汉字严为例，Unicode 码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E 在前，25在后，这就是 Big endian 方式；25在前，4E 在后，这是 Little endian 方式。</p><p>第一个字节在前，就是”大头方式”（Big endian），第二个字节在前就是”小头方式”（Little endian）。</p><p>那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？</p><p>Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。</p><p>如果一个文本文件的头两个字节是 FE FF，就表示该文件采用大头方式；如果头两个字节是 FF FE，就表示该文件采用小头方式。</p><p>参考资料：</p><blockquote><p> <a href="https://zhuanlan.zhihu.com/p/658651404">字符编码技术专题(一)：快速理解ASCII、Unicode、GBK和UTF-8</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、-ASCII-码&quot;&gt;&lt;a href=&quot;#一、-ASCII-码&quot; class=&quot;headerlink&quot; title=&quot;一、 #ASCII 码&quot;&gt;&lt;/a&gt;一、 #ASCII 码&lt;/h2&gt;&lt;p&gt;计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 </summary>
      
    
    
    
    <category term="后端" scheme="https://www.lazydaily.cn/categories/%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="编码" scheme="https://www.lazydaily.cn/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>关于oracle中以Blob字段查找重复值问题</title>
    <link href="https://www.lazydaily.cn/761386768996883/"/>
    <id>https://www.lazydaily.cn/761386768996883/</id>
    <published>2020-08-31T16:00:00.000Z</published>
    <updated>2025-05-20T07:21:20.742Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题产生"><a href="#问题产生" class="headerlink" title="问题产生"></a>问题产生</h2><p>最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就是 <code>Group by</code> 方法。</p><h2 id="库表结构（简单的还原一下库表）"><a href="#库表结构（简单的还原一下库表）" class="headerlink" title="库表结构（简单的还原一下库表）"></a>库表结构（简单的还原一下库表）</h2><pre><code class="language-sql">create table cs(id int PRIMARY KEY not null,name NVARCHAR2(50) not null,jl blob not null);select * from cs;insert into cs  select 1,&#39;Tom&#39;,to_blob(&#39;123412f&#39;) from dual;insert into cs  select 2,&#39;King&#39;,to_blob(&#39;123412f&#39;) from dual;insert into cs  select 3,&#39;Leo&#39;,to_blob(&#39;124123F21F&#39;) from dual;</code></pre><p><img src="/img/f3627e8bb0dc4f0b8e589df10f6fe863.png" alt="库表结构"></p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><h4 id="1-通过Group-by-方式进行查重（操作失败）"><a href="#1-通过Group-by-方式进行查重（操作失败）" class="headerlink" title="1.通过Group by 方式进行查重（操作失败）"></a>1.通过Group by 方式进行查重（操作失败）</h4><p>遇到这个问题，我熟啊！写 <code>group by</code> 语句就行了呗，然后就写了这样的语句</p><pre><code class="language-sql">select  jl,count(1) from cs group by jl having count(1)&gt;1;</code></pre><p>当我美滋滋开始执行的时候，却出现的问题<br><img src="/img/584082192807448bb4db57a334ebb740.png" alt="问题1"><br>查了查相关资料知道了，oralce是不能通过blob类型的字段进行 <code>group by</code> 的，那我把这个字段用 <code>to_char()</code> 转换一下试试看</p><pre><code class="language-sql">select jl,count(1) from cs group by to_char(jl) having count(1)&gt;1;</code></pre><p><img src="/img/6576c5fe4a184619b7fe4897d6ea30af.png" alt="问题2"><br>显然，<code>group by</code> 也不能后跟 <code>to_char()</code> 函数。那我只能是自己写语句吧。</p><h4 id="2-自己写语句查重"><a href="#2-自己写语句查重" class="headerlink" title="2.自己写语句查重"></a>2.自己写语句查重</h4><p>如果不能用group by 进行查重的话，只能是自己写查重语句，然后就写了如下语句</p><pre><code class="language-sql">select * from cs t1 where exists (select 1 from cs t2 where to_char(t2.jl) = to_char(t1.jl) and t2.id !=t1.id);</code></pre><p>需要注意的是blob类型字段是不能直接&#x3D;，需要 <code>to_char()</code> 转换，这个语句就执行成功了。结果如下，问题解决。<br><img src="/img/35a289c650094738966c332480bc7da5.png" alt="结果1"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题产生&quot;&gt;&lt;a href=&quot;#问题产生&quot; class=&quot;headerlink&quot; title=&quot;问题产生&quot;&gt;&lt;/a&gt;问题产生&lt;/h2&gt;&lt;p&gt;最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就</summary>
      
    
    
    
    <category term="数据库" scheme="https://www.lazydaily.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="oracle" scheme="https://www.lazydaily.cn/tags/oracle/"/>
    
    <category term="开发问题" scheme="https://www.lazydaily.cn/tags/%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
</feed>
